
requirements engineering journal manuscript no.(will be inserted by the editor)


causality in requirements artifacts: prevalence,detection, and impact


julian frattini · jannik fischbach ·daniel mendez · michaelunterkalmsteiner · andreas vogelsang ·krzystof wnuk


received: date / accepted: date


abstract background: causal relations in natural language (nl) require-ments convey strong, semantic information. automatically extracting suchcausal information enables multiple use cases, such as test case generation, butit also requires to reliably detect causal relations in the ﬁrst place. currently,this is still a cumbersome task as causality in nl requirements is still barely un-derstood and, thus, barely detectable. objective: in our empirically informedresearch, we aim at better understanding the notion of causality and support-ing the automatic extraction of causal relations in nl requirements. method:in a ﬁrst case study, we investigate 14.983 sentences from 53 requirements doc-uments to understand the extent and form in which causality occurs. second,we present and evaluate a tool-supported approach, called cira, for causalitydetection. we conclude with a second case study where we demonstrate theapplicability of our tool and investigate the impact of causality on nl require-ments. results: the ﬁrst case study shows that causality constitutes around28 % of all nl requirements sentences. we then demonstrate that our detectiontool achieves a macro-f1 score of 82 % on real-world data and that it outper-forms related approaches with an average gain of 11.06 % in macro-recall and11.43 % in macro-precision. finally, our second case study corroborates the


j. frattini, k. wnuk, m. unterkalmsteinerblekinge institute of technology, swedene-mail: ﬁrstname.lastname@bth.se


j. fischbachqualicen gmbh, germany, and university of cologne, germanye-mail: jannik.ﬁschbach@qualicen.de


d. mendezblekinge institute of technology, sweden, and fortiss gmbh, germanye-mail: daniel.mendez@bth.se


a. vogelsanguniversity of cologne, germanye-mail: vogelsang@cs.uni-koeln.de


arxiv:2112.08265v1  [cs.se]  15 dec 2021


2frattini et al.


positive correlations of causality with features of nl requirements. conclu-sion: the results strengthen our conﬁdence in the eligibility of causal relationsfor downstream reuse, while our tool and publicly available data constitute aﬁrst step in the ongoing endeavors of utilizing causality in re and beyond.


keywords causality · multi case study · requirements engineering ·natural language processing


1 introduction


motivation sentences containing causal relations, for example “a conﬁrma-tion message shall be shown if the system has successfully processed the data.”,are often used to capture the intended behavior of a system. in fact, causal re-lations are inherently embedded in many textual descriptions of requirements.both understanding the extent of use, but also detecting and reliably extract-ing these causal relations, provide great potential for applications in the do-main of requirements engineering (re). among these are, for instance, sup-porting the automated test case generation [17,16] or facilitating reasoningabout inter-requirements dependencies [15]. however, the automated extrac-tion of causal relations from requirements is still challenging for two reasons:on the one hand, even though controlled natural language in re [20,35] aimsto minimize ambiguity and can easily be reused for further formalization [46,23], unrestricted natural language is still predominantly used in re [50]. thiscomplicates information retrieval from requirements due to the inherent com-plexity and ambiguity of nl. on the other hand, causal relations can occurin diﬀerent forms [3] such as marked/unmarked (i.e., containing a cue phraseindicating the causal relationship) or explicit/implicit (i.e., explicitly statingboth the cause and the eﬀect), further rendering the identiﬁcation and extrac-tion of causes and eﬀects cumbersome. existing approaches still fail to extractcausal relations from nl with a performance that allows for eﬃcient and reli-able use in practice [1]. we therefore argue that a novel method for detectingand extracting causal relations from requirements is imperative for the eﬀec-tive utilization of causality in re.


contribution causality extraction entails two distinct challenges: ﬁrst, oneneeds to determine whether a requirement contains causal relations. only sen-tences containing causal relations are eligible for extraction, so sentences con-taining no causal relations can be discarded. second – if they contain causalrelations – these need to be properly understood and extracted. addressingboth challenges requires comprehending to which extent, form, and complex-ity causality occurs in practice in re. reliable knowledge about the distribu-tion of causality is a necessary precondition to develop eﬃcient approaches forthe automated detection and extraction of causal relations. however, empir-ical evidence on causality in requirements artifacts is still unavailable to thisday. in this manuscript, we report on how we addressed those challenges toclose the existing research gap by making the following contributions (c):


causality in requirements artifacts: prevalence, detection, and impact3


c 1 prevalence of causality: we report on an exploratory case study ana-lyzing the extent, form, and complexity of causality in requirements rootedin 14,983 sentences and emerging from 53 requirement documents, whichoriginate from 18 diﬀerent domains. we corroborate that causality tends tooccur predominantly in explicit and marked form, and that about 28 % ofthe analyzed sentences contain causal information about the expected sys-tem behavior. this strengthens our conﬁdence in the relevance of causalityand, in consequence, of our approach to automatically extract causality.


c 2 automated detection of causality: we present our tool-supportedapproach cira (causality in requirement artifacts), which constitutes aﬁrst step towards causality extraction from nl requirements by automat-ically detecting causal relations in nl requirements. we train and empiri-cally evaluate cira using the pre-analyzed data set and achieve a macro-f1 score of 82 %. compared to baseline systems that classify causality re-lying on the presence of certain cue phrases, or shallow ml models, ciraleads to an average performance gain of 11.43 % in macro-precision and11.06 % in macro-recall.


c 3 impact of causality: we report on a second exploratory case studyevaluating the correlation between the occurrence of causality and its ef-fects on the requirements life cycle, not only demonstrating a possible usecase of the automatic causality detection approach and tool but also cor-roborating the positive impact on causality on the requirements process.


c 4 open data and source code: to strengthen the transparency and,thus, the credibility of our research, but also to facilitate independent repli-cations, we publicly disclose our tool, code, and data set used in the casebert. our code and annotated data sets can be found at https://doi.org/10.5281/zenodo.5596668.


1.1 previously published material


this manuscript extends our previously published conference paper [14] in thefollowing aspects: we extend our case study (c1) and development of our ownapproach (c2) by the aforementioned second case study (c3) based on anextensive data set of requirements from a multinational software developmentcompany. in addition, we expand the evaluation of the resulting data from theﬁrst case study in response to discussions with the requirements engineeringcommunity to increase the generalizability of our results. please note that wetook the liberty of intentionally reusing minor parts of our previously publishedmaterial for this manuscript at hand in a verbatim manner, such as discussionson related work or terminological deﬁnitions.


4frattini et al.


1.2 outline


the manuscript is structured as follows: sect. 2 introduces the terminologyused throughout the manuscript based on established literature. sect. 3 reportson the ﬁrst case study investigating the extent, form, and complexity to whichcausality is used in nl requirements (c1). our approach for automaticallydetecting causal requirements (c2) is presented in sect. 4. sect. 5 reports onthe second case study (c3) investigating the impact of causality in naturallanguage requirements on their life cycle. sect. 6, ﬁnally, presents related workin the research area before concluding our work with sect. 7.


2 terminology


the concept of causality has received notable attention in the studies of variousdisciplines, e.g., in psychology [53]. before investigating the extent to whichcausality occurs in requirements, we elaborate on a deﬁnition of causality.


concept of causality causality describes a relation between at least two events:a causing event (the cause) and a caused event (the eﬀect). an event is com-monly deﬁned as “any situation (including a process or state) that happensor occurs either instantaneously (punctual) or during a period of time (dura-tive)” [39]. the connection between causes and eﬀects is counterfactual [34]: ifa cause c1 does not occur, then an eﬀect e1 cannot occur either. consequently,a causal relation entails that the eﬀect may only occur if and only if the causehas occurred. if this is not the case, then the relation might be confounded andis hence not causal. this relation can be interpreted in the view of booleanalgebra as an equivalence between a cause and eﬀect (c1 ⇔e1): if the causeis true, the eﬀect is true and if the cause is false, the eﬀect is also false. therepresentation of a causal relationship as a logical equivalence is not entirelyreﬂecting the nature of the relation, especially in regards to the temporal or-der of events, which is not determined in propositional logic. the challenges offormalizing causal relationships both regarding the used notation and the am-biguity when interpreting these relationships are discussed in depth in a dif-ferent paper [13]. for the remainder of this manuscript, we use the notationof a logical equivalence to represent a causal relationship. we refer the readerinterested in an extended discussion on the logical formalization of causal re-lationships to our previous publication on the matter [13]. the type of causalrelation between the two events can take one of three diﬀerent forms [52]: acausing, enabling, or preventing relationship.


– c1 causes e1: if c1 occurs, e1 also occurs (c1 ⇔e1). this can be illustratedby req 1: “after the user enters a wrong password, a warning windowshall be shown.” in this case, the wrong input is the trigger to display thewindow.


– c1 enables e1: if c1 does not occur, e1 does not occur either (e1 is notenabled, (¬c1 ⇔¬e1)). req 2: “as long as you are a student, you are


causality in requirements artifacts: prevalence, detection, and impact5


allowed to use the sport facilities of the university.” only the student statusenables to do sports on campus.


– c1 prevents e1: if c1 occurs, e1 does not occur (c1 ⇔¬e1). req 3: “dataredundancy is required to prevent a single failure from causing the loss ofcollected data.” there will be no data loss due to data redundancy.


temporal ordering of causes and eﬀects causes and eﬀects can be related toeach other in three temporal ways [39]. in the ﬁrst temporal relation, the causeoccurs before the eﬀect (before relation). in req 1, the user has to enter awrong password before the warning window will be displayed. in this example,the cause and eﬀect represent two punctual events. in the second temporalrelation, the occurrence of the cause and eﬀect overlaps: “the ﬁre is burningdown the house.” in this case, the occurrence of the emerging ﬁre overlaps withthe occurrence of the increasingly brittle house (overlaps relation). in the thirdtemporal relation (during relation), cause and eﬀect occur simultaneously.req 2 describes such a relation: the eﬀect – being allowed to do sports on thecampus – is only valid as long as one has the student status. the start andend time of the cause is therefore also the start and end of the eﬀect. here,both events are durative.


forms of causality the form in which causality can be expressed has threefurther characteristics [3]: marked and unmarked causality, explicit and im-plicit causality, and ambiguous and non-ambiguous regarding its cue phrases,a linguistic concept commonly used when dealing with causality in naturallanguage [22,5]. a cue phrase is deﬁned as “a word, a phrase, or a word pat-tern, which connects one event to the other with some relation” [5] and there-fore a lexical indicator for the causal relationship.


– marked and unmarked: a causal relation is marked if a certain cuephrase indicates its causality. the requirement “if the user presses thebutton, a window appears” is marked by the cue phrase “if”, while “theuser has no admin rights. he cannot open the folder.” is unmarked.


– explicit and implicit: an explicit causal relation contains informationabout both the cause and eﬀect. the requirement “in case of an error, thesystems prints an error message to the console” is explicit since it containsboth the cause (error) and eﬀect (error message). “a parent process kills achild process” is implicit because the eﬀect that the child process is termi-nated is not explicitly stated. implicitly causal sentences are particularlyhard to process and might be a potential source of ambiguity in re dueto their obscuring nature.


– ambiguous and non-ambiguous cue phrases: due to the speciﬁcityof most cue phrases in marked causality, it seems feasible to deduce theclassiﬁcation of a sentence as containing causality based on the occurrenceof certain cue phrases. however, certain cue phrases (e.g., since) indicatecausality, but also occur in other contexts (e.g., denoting time constraints).such cue phrases are called ambiguous, while cue phrases (e.g., because)that predominantly indicate causality are called non-ambiguous.


6frattini et al.


complexity of causality all previous examples use the complexity-wise sim-plest form of causality where the causal relation consists of one single cause andone single eﬀect. due to the increasing complexity of systems, however, the ex-pected behavior is described by multiple causes and eﬀects that are connectedto each other. they can be linked either by conjunctions (c1 ∧c2 ∧· · · ⇔e1)or disjunctions (c1 ∨c2 ∨· · · ⇔e1) or a combination of both. furthermore,the constituents of causal relations can be contained in more than one sen-tence, which is a signiﬁcant challenge for causality extraction as it increasesthe scope of causality detection beyond one single sentence. therefore we alsoconsider two-sentence causality. however, causal relations scattered over morethan two adjacent sentences are not considered in this research work. addi-tionally, the complexity increases when several causal relations are linked to-gether, i.e., if the eﬀect of a relation r1 represents a cause in another rela-tion r2. we deﬁne such causal relations, where r2 is dependent on r1, as eventchains (e.g., r1 : c1 ⇔e1 and r2 : e1 ⇔e2).


3 case study 1: prevalence of causality in requirement artifacts


we designed and conducted the case study following the well-established guide-lines of runeson and h¨ost [45]. our case study is of exploratory nature basedon the classiﬁcation of robson [44], as we aim to unravel new insights intocausality in requirement artifacts. in this section, we describe our researchquestions, study objects, study design, study results, and threats to validity. weconclude by giving an overview of the implications of the study on causalitydetection and extraction from nl requirements.


3.1 research questions


our goal in understanding the prevalence of causality in requirements arti-facts encompasses the extent, form, and complexity of causality. based on theterminology previously established in sect. 2, we investigate the following re-search questions (rq) in the scope of this ﬁrst case study:rq 1 to which degree does causality occur in requirement documents?rq 2 how often do the relations cause, enable, and prevent occur?rq 3 how often do the temporal relations before, overlap, and during occur?rq 4 in which form does causality occur in requirement documents?


– rq 4a: how often does marked and unmarked causality occur?– rq 4b: how often does explicit and implicit causality occur?– rq 4c: which causal cue phrases are used? are they mainly ambiguousor non-ambiguous?


rq 5 at which complexity does causality occur in re documents?


– rq 5a: how often do multiple causes occur?– rq 5b: how often do multiple eﬀects occur?– rq 5c: how often does two-sentence causality occur?


causality in requirements artifacts: prevalence, detection, and impact7


– rq 5d: how often do event chains occur?


rq 6 is the distribution of labels in all categories domain-independent?


3.2 study objects


to obtain evidence on the extent to which causality is used in requirements ar-tifacts in practice, we had to generate a large and representative collection ofartifacts. we considered data sets as eligible for our case study based on threecriteria: 1) the data set shall contain requirements artifacts that are/were usedin practice, 2) the data set shall not be domain-speciﬁc, but rather containartifacts from diﬀerent domains, and 3) the documents shall originate from atime frame of at least 10 years. following these criteria ensures that our anal-ysis is not restricted to a single year or domain, but rather allows for a com-prehensive and generalizable view on causality in requirements. we accord-ingly selected the data set provided by fischbach et al. [15]. to the best ofour knowledge, this data set is currently the most extensive collection of re-quirements available to the research community. from its 463 documents con-taining 212k extracted and pre-processed sentences, we randomly selected 53documents from the data set for our analysis. our ﬁnal data set consists of14,983 sentences from 18 diﬀerent domains (see fig. 1).


3.3 study design


model the phenomenon answering the research questions in the scope of ourﬁrst case study entails to annotate the sentences of our data set with respectto the categories elicited in sect. 2. for example, each causal sentence has tobe classiﬁed in the category explicit as either explicit or implicit. accordingto pustejovsky and stubbs [43], the ﬁrst step in each annotation process is to“model the phenomenon” that needs to be annotated. speciﬁcally, the phe-nomenon should be deﬁned as a model m that consists of a vocabulary t, therelations r between the terms as well as the interpretations i of terms. rq 1can be understood as a binary annotation problem, which can be modeled as:


– t: {sentence, causal, not causal}– r: {sentence ::= causal | not causal}– i: {causal = “a sentence is causal if it contains a relation between at leasttwo events, where e1 causes the occurrence of e2”, ¬causal = “a sentenceis not causal if it describes a state that is independent on any events”}explicitly modeling an annotation problem according to the aforementionedframework does not only contribute an unambiguous deﬁnition of the researchproblem but can also be used as a guideline for the annotators explaining themeaning of the labels. each rq has been modeled accordingly and commu-nicated with all annotators. in addition to interpretation i, we have also pro-vided an example for each label to avoid misunderstandings. the following ninecategories emerged in the process of modeling rq 1-5, according to which we


8frattini et al.


aerospace


agriculture


astronomy


automotive


banking


data analytics


digital library


digital society


energy


health


infrastucture


insurance


military


physics


regulatory


smart city


sustainability


telecomm.


0


1000


2000


3000


4000


5000


# sentences


5510


295239157


376


2700


19810722


1164


776


1244232


27


1514


1032


578


domain distribution


2004


2005


2006


2007


2008


2009


2010


2011


2012


2013


2014


2015


2016


2017


2018


2019


unknown


0


1


2


3


4


5


6


7


8


# documents


2


5


22


0


1


33


4


3


11


8


2


6


4


6


yearly distribution


fig. 1: descriptive statistics of our data set. the upper graph shows the num-ber of sentences per domain. the lower graph depicts the year of creation perdocument.


annotated our data set: causality , explicit , marked , single sentence ,


single cause , single eﬀect , event chain , relationship and temporality .


we refer to all categories except causality as dependent categories, as they


are dependent on the causality label. to answer rq 6, we perform a strat-iﬁed analysis for each of the aforementioned categories using the domains asstrata. due to the imbalance of the data set in respect to the domains the re-quirements sentences originate from, we formulate the following null hypoth-esis for each category x: sentences from diﬀerent domains have the same dis-tribution of values in category x.


annotation environment we developed our own annotation platform tailoredto our research questions.2 in contrast to other annotation platforms [40] whichonly show single sentences to the annotators, we also display the predecessorand successor of each sentence, which is required to determine whether thecausal relation is not conﬁned to one sentence, but extends across two (see rq





causality in requirements artifacts: prevalence, detection, and impact9


table 1: inter-annotator agreement statistics per category. the two categories“relationship” and “temporality” were jointly labeled by the ﬁrst and secondauthor and therefore do not require a reliability assessment.


causalityexplicitmarked


singlesentence


singlecause


singleeﬀect


eventchainavg.


01010101010101


confusion0203419324251221284177637245027


matrix12744993941112464174624333846318139


agreement84.4 %87.2 %93.1 %95.0 %76.0 %76.4 %92.0 %86.3 %


cohen’s kappa0.5790.3580.0230.4640.2610.3620.270.331


gwet’s ac10.7530.840.9260.9450.6450.6250.910.806


5c). for the binary annotation problems (see rq 1, rq 4a, rq 4b, rq 5a - d),we provide two labels for each category. cue phrases present in the sentencecan be manually selected by either choosing from a list of already identiﬁedcue phrases or by adding a new cue phrase using a text input ﬁeld (see rq 4c).since rq 2 and rq 3 are ternary annotation problems, the platform providesthree labels for these categories.


annotation guideline to ensure a common understanding both of causalityitself and of the respective categories, we conducted a workshop with all anno-tators prior to the labeling process. the results of the workshop were recordedin the form of an annotation guideline. all annotators were instructed to com-ply with all of the annotation rules. one important, initially counter-intuitiveinstruction was to not entirely depend on the occurrence of cue phrases, as thisapproach is prone to introducing too many false positives. rather than focus-ing on lexical or syntactic attributes, the annotation process has to be initi-ated by fully reading the sentence and comprehending it on a semantic level.the impact of this becomes evident when considering some examples: require-ments like “if the gaseous nitrogen supply is connected to the ecs duct sys-tem, ecs shall include the capability of monitoring the oxygen content in theducting.” are easy to classify as causal due to the occurrence of the cue phraseif and the explicit phrasing of both the cause and the eﬀect. requirements con-taining a relative clause like “any items or issues which will limit the optionsavailable to the platform developers should be described.” are more diﬃcult tocorrectly classify due to the lack of cue phrases. the semantically equivalentparaphrase “if an item or issue will limit the options available to the platformdevelopers, the item or issue should be described.” reveals the causal relationcontained by the requirement. a second vital instruction was to check if thecause is really necessary for the eﬀect to occur. only if the existence of thecause is mandatory for the eﬀect to happen, the relation can be deemed causal.


annotation validity we utilize the calculation of the inter-annotator agree-ment to verify the reliability of our annotations. each of the six annotatorswas assigned 3,000 sentences, of which 2,500 were unique and 500 overlapping.


10frattini et al.


consequently, among the approximately 15,000 annotated sentences 3,000were labeled by two annotators. to maximize the meaningfulness of the inter-annotator agreement, the 500 overlapping sentences were selected in batchesof 100, such that every annotator had an overlap with every other annotator.based on the overlapping sentences, we calculated the cohen’s kappa [6] mea-sure to evaluate how well the annotators made the same annotation decisionfor a given category. we chose cohen’s kappa since it is widely used for assess-ing inter-rater reliability [49]. however, a number of statistical problems areknown to exist with this measure [36]. in case of a high imbalance of ratingscohen’s kappa is low and indicates poor inter-rater reliability even if thereis a high agreement between the raters (kappa paradox [11]). thus, the cal-culation of cohen’s kappa is not meaningful in such scenarios. consequently,studies [54] suggest that cohen’s kappa should always be reported togetherwith the percentage of agreement and other paradox resistant measures (e.g.,gwet’s ac1 measure [25]) in order to make a valid statement about the inter-rater reliability. we involved six annotators in the creation of the corpus andassessed the inter-rater reliability on the basis of 3,000 overlapping sentences,which represent about 20 % of the total data set. we calculated all measuresusing the cloud-based version of agreestat [24]. cohen’s kappa and gwet’sac1 can both be interpreted using the taxonomy developed by landis andkoch [32]: values ≤0 as indicating no agreement and 0.01–0.20 as none to0.81–1.00 as almost perfect agreement. table 1 provides an overview of theconfusion matrices and calculated agreement measures per category. the inter-rater agreement for the category causality was calculated on the basis of all3000 overlapping sentences. since the other categories represent speciﬁc formsof causality, we computed their inter-rater agreement only on the sentencesmarked as causal. our analysis demonstrates that the inter-rater agreement ofour annotation process is reliable. across all categories, an average percentageof agreement of 86 % was achieved. except for the categories single cause


and single eﬀect , all categories show a percentage of agreement of at least84 %. we hypothesize that the slightly lower value of 76 % for these twocategories is caused by the fact that in some cases the annotators interpretthe causes and eﬀects with diﬀerent granularity (e.g., annotators might breaksome causes and eﬀects down into several sub causes and eﬀects, while somedo not). hence, the annotations diﬀer slightly. the kappa paradox is partic-ularly evident for the categories marked and event chain . despite a highagreement of over 90 %, cohen’s kappa yields a very low value, which “para-doxically” suggests almost no or only fair agreement. a more meaningful as-sessment is provided by gwet’s ac1 as it did not fail in the case of prevalenceand remains close to the percentage of agreement. across all categories, themean value is above 0.8, which indicates a nearly perfect agreement. there-fore, we assess our labeled data set as reliable and suitable for further analy-sis and the implementation of our causality detection approach.


causality in requirements artifacts: prevalence, detection, and impact11


28.13


71.87


89.42


10.58


84.6


15.4


92.81


7.19


80.9


19.1


79.17


20.83


6.88


93.12


33.58


56.62


9.8


48.49


42.73


8.78


causalityexplicitmarkedsingle sentencesingle causesingle effectevent chainrelationshiptemporality


0


25


50


75


100


fraction of sentences in %


causality


not causal


causal


explicit


implicit


explicit


marked


unmarked


marked


single sentence


two sentence


single sentence


single cause


several causes


one cause


single effect


several effects


one effect


event chain


no event chain


event chain


relationship


prevent


enable


cause


temporality


overlap


during


before


fig. 2: annotation results per category. the y axis of the bar plot for thecategory “causality” refers to the total number of analyzed sentences. theother bar plots are only related to the causal sentences.


data analysis rq 1-5 are answered by providing descriptive statistics of thedistribution of labels for each category. for rq 6, inferential statistics are ap-plied. since the hypotheses formulated for each category aim to investigatethe independence between the association of a requirement to a speciﬁc do-main and the distribution in the respective category, a statistical hypothesistest for independence can be used. as both the independent variable (the do-main) and the dependent variable (the respective category) are categorical,the chi-squared test will be used. the category causality is tested with re-spect to the full annotated data set. all dependent categories are tested onthe causal subset of the data since only causal sentences are annotated in theother categories. for all tests, only domains with at least 100 sentences wereselected as eligible strata to conﬁne the hypothesis tests to suﬃciently repre-sented domains. this threshold was introduced to rq 6 to avoid the noise ofunderrepresented domains. since the data set was aggregated in rq 1-5, thischange is only necessary for rq 6. using the subset of domains as strata im-plies the degree of freedom of the chi-squared tests exceeding 2, hence therisk of the multiple comparison problem, i.e., the likelihood for a type i er-ror in rejecting null hypotheses, arises [2]. for example, when evaluating thenull-hypothesis of independence for the dichotomous category explicit , con-sidering the nine eligible domains with more than 100 causal sentences yields


12frattini et al.


aerospace


astronomy


banking


data analytics


health


infrastructure


smart city


sustainability


telecomm


0%


20%


40%


60%


80%


100%


fraction of explicit sentences


88.4%


95.3%93.5%91.7%93.1%90.6%


86.1%


80.4%


86%


fig. 3: percentage of sentences labeled “explicit” within domains containingat least 100 causal sentences


a degree of freedom of 8, as it is calculated as follows [37] (considering thatthe number of rows is 2 for dichotomous variables):


dof = (number of rows−1)∗(number of columns−1) = (2−1)∗(9−1) = 8 (1)


the p-value of the chi-squared test of this hypothesis is 0.000036, far belowthe signiﬁcance level α = 0.05, even though the relative number of values in thecategory explicit among the eligible domains suggests an equal distributionand therefore independence of the domain, as seen in fig. 3. hence, instead ofreporting the in this case not meaningful p-value of the chi-square hypothesistest we perform a bonferroni correction [2] on the signiﬁcance level and per-form the chi-squared test in each category for each domain against the sum ofall samples outside of the domain, as applied in similar scenarios [33]. applyingthe bonferroni correction to the signiﬁcance level based on the following for-mula [2] yields a signiﬁcance level that counteracts the large degree of freedomm and reduces the likelihood of type i errors when refuting null hypotheses:


pc = α


m = 0.5


8 = 0.00625(2)


the previously calculated p-value for the chi-square test of independence con-sidering all domains still suggests to reject the null hypothesis. hence, a post-hoc test similar to [33], where each domain is compared to the sum of all otherdomains, is applied to reveal, that only the null-hypothesis for the domainsustainability can be refuted with a p-value of 0.0001 < 0.00625, which alignswith fig. 3. this procedure is applied to all hypotheses of rq 6.


3.4 study results


the results of each labeled category are visualized in fig. 2. detailed valuesfor the distribution of labels among all categories and domains are given intable 11. when interpreting the values, it is important to note that for our


causality in requirements artifacts: prevalence, detection, and impact13


analysis we consider complete requirement documents. consequently, our dataset contains records with diﬀerent contents, which do not necessarily representall functional requirements. for example, requirement documents also containnon-functional requirements, phrases for content structuring, purpose state-ments, etc. the results are hence to be interpreted in respect to the contentof a full requirements artifact, not only to its functional requirements.answer to rq 1: fig. 2 conﬁrms that causality occurs in requirementdocuments to a signiﬁcant extent. about 28 % of the analyzed sentences arecausal. from this result, we can conclude that causality is a major linguisticelement of requirement artifacts as almost one-third of all sentences are causal.answer to rq 2: the majority (56 %) of causal sentences contained inrequirement artifacts represent an enable relationship between certain events.only about 10 % of the causal sentences indicate a prevent relationship. causerelationships are found in about 34 % of the annotated data.answer to rq 3: interestingly, we found that causes and eﬀects occuralmost equally often in a before and during relation. with about 48 %, thebefore relation is the most frequent temporal relation in our data set, but onlywith a diﬀerence of about 6 % compared to the during relation. the overlaprelation occurred only in a minority (8.78 % of the sentences).answer to rq 4a: the majority of causal sentences contain one or morecue phrases, as fig. 2 indicates, to indicate the causal relationship betweencertain events. only around 15 % of the labeled sentences were categorized asunmarked causality.answer to rq 4b: most causal sentences are explicit, i.e., they containinformation about both the cause and the eﬀect. only about 10 % of causalsentences are implicit.answer to rq 4c: all causal cue phrases identiﬁed in the investigatedrequirements artifacts are listed in tab. 2. the left side of the table showsthe cue phrases ordered by word group. on the right side, all verbs used toexpress causal relations are listed. the verbs are further ordered according towhether they express a cause, enable, or prevent relationship. to assess theambiguity of a cue phrase x, we formulate a binary classiﬁcation task: considerall sentences as the sample space. the causal sentences of that sample spacerepresent the relevant elements. the precision of cue phrase x as a selectioncriterion for causal sentences is the conditional probability, that a sentencefrom the sample space is causal given that it contains cue phrase x, and hencereﬂects the ambiguity of the cue phrase:


pr(sentence is causal | sentence contains x) =


pr(sentence is causal ∩sentence contains x)


pr(sentence contains x)(3)


a high precision value indicates a non-ambiguous cue phrase, i.e., the occur-rence of the cue phrase in a sentence is a strong indicator for the sentence be-ing causal, while low values indicate strongly ambiguous cue phrases. tab. 2demonstrates that a number of diﬀerent cue phrases are used to express causal-ity in requirement documents. not surprisingly, cue phrases like “if”, “because”


14frattini et al.


aerospace


agriculture


astronomy


automotive


banking


data analytics


digital library


digital society


health


infrastructure


physics


smart city


sustainability


telecomm


0.0%


10.0%


20.0%


30.0%


40.0%


fraction of causal sentences


30.2%


19.3%


44.4%


24.2%


37%


24.9%


27.8%


41.1%


32.5%


35.8%


39.2%


22.9%


17.8%


27.2%


fig. 4: distribution of causality among domains


and “therefore” show precision values of more than 90 %. however, there is avariety of cue phrases that indicate causality in some sentences but also oc-cur in other non-causal contexts. this is especially evident in the case of pro-nouns. relative sentences can indicate causality, but not in every case, whichis reﬂected by the low precision value of for example which. a similar patternemerges with regard to the used verbs. only a few verbs (e.g., “leads to, de-grade, and enhance”) show a high precision value. consequently, the major-ity of used pronouns and verbs do not necessarily indicate a causal relation ifthey are present in a sentence.answer to rq 5a: fig. 2 illustrates that most causal relations in require-ment documents include only a single cause. multiple causes occur in only19.1 % of the analyzed causal sentences. the exact number of causes was notdocumented during the annotation process. however, the participating annota-tors reported consistently that two to three causes were predominantly preva-lent in the case of complex causal relations. more than three causes were rare.answer to rq 5b: interestingly, the distribution of eﬀects is similarto that of causes. likewise, single eﬀects occur signiﬁcantly more often thanmultiple eﬀects. according to the annotators, the number of eﬀects in the caseof complex relations is mostly limited to a maximum of two eﬀects. three ormore eﬀects occur rarely.answer to rq 5c: most causal relations can be found in single sentences.relations, where cause and eﬀect are distributed over two sentences, occur onlyin about 7 % of the analyzed data. among the marked subset of these sentences(n = 242) the cue phrase “therefore” was used most frequently, occurring 58times. the next-most frequent cue phrase, “thus”, appeared only 14 times.answer to rq 5d: fig. 2 shows that event chains are rarely used in re-quirement documents. most causal sentences contain isolated causal relations,while only roughly 7 % contain event chains.answer to rq 6 fig. 4 visualizes the distribution of causality amongall domains which are represented with more than 100 sentences. as the per-centage of causal sentences ranges from 17.8 % up to 44.4 %, we can as-sume that causality is indeed a phenomenon occurring in all eligible domains.


causality in requirements artifacts: prevalence, detection, and impact15


table 2: overview of cue phrases used to indicate causality in requirement doc-uments. bold precision values highlight non-ambiguous phrases that mostlyindicated causality (pr(causal | x is present in sentence) ≥0.8).


typephrasecausalnot causalprecisiontypephrasecausalnot causalprecision


conjunctionsif387410.90causeforce(s/ed)21180.54as60713130.32cause(s/ed)32100.76because7870.92lead(s) to501.00but1002040.33reduce(s/ed)48280.63in order to141330.81minimize(s/ed)28110.72so (that)88860.51aﬀect(s/ed)13190.41unless2340.85maximize(s/ed)1150.69while71900.44eliminate(s/ed)8110.42once48150.76result(s/ed) in50430.54except950.64increase(s/ed)49340.59as long as1210.92decrease(s/ed)580.38


adverbstherefore6160.91impact(s)37680.35when331640.84degrade(s/ed)1120.85whenever1001.00introduce(s/ed)11120.48hence2190.70enforce(s/ed)210.67where2131500.59trigger(s/ed)1170.61then111700.61imply7140.33since65320.67attain(s/ed)3130.18consequently260.25create(s/ed)39880.30wherever520.71impose(s/ed)7130.35rather16300.35perform(s/ed)26600.30


to this/that end1201.00enabledepend(s) on28210.57thus66170.80require(s/ed)3162620.55for this reason730.70allow(s/ed)1871300.59due to91260.78need(s/ed)981620.38thereby420.67necessitate(s/ed)720.78as a result1140.73facilitate(s/ed)29280.51for this purpose120.33enhance(s/ed)1640.80


pronounswhich2776080.31ensure(s/ed)145660.69who28520.35achieve(s/ed)30240.56that73211780.38support(s/ed)1283010.30whose16110.59enable(s/ed)75360.68


adjectivesonly1271260.50permit(s/ed)10130.43prior to26200.57rely on350.38imperative130.25measure(s/ed)992470.28necessary (to)36190.65provide(s/ed)751250.37given731400.34get13230.36following531750.23meet42340.55


prepositionfor120927530.31preventhinder(s/ed)110.50during3271370.70prevent(s/ed)38170.69after133570.70avoid(s/ed)14230.38by50611710.30mitigate(s/ed)380.27with68015540.30


in the course of210.67


through1142040.36


as part of19510.27


in this case1830.86


before54270.67


until33110.75


upon25480.34


in case of3070.81


in both cases101.00


in the event of1520.88


in response to670.46


in the absence of810.89


within1503150.32


as far as450.44


according to21540.28


around25410.37


from3709900.27


based on561750.24


the chi-squared test reported in tab. 3 suggests rejecting the null hypothe-sis for domain-independence for 10 out of 14 eligible domains considering thebonferroni-corrected signiﬁcance level. we can conclude that causality is aphenomenon observable independent of the domain from which requirementsoriginate, but the extent to which causality occurs diﬀers with statistical sig-niﬁcance. for all dependent categories, the domains aerospace, astronomy,banking, data analytics, health, infrastructure, smart city, sustainability,and telecomm are eligible for consideration as they contain more than 100causal sentences. on the right side of tab. 3 each cell contains the p-value fora chi-squared test comparing the distribution of the given domain to the rest


16frattini et al.


table 3: bonferroni-corrected chi-squared tests of independence from the do-main. cells preﬁxed with * indicate a category, where the distribution of thegiven domain diﬀers signiﬁcantly from the sample.


domaincausalexplicitmarkedsinglecausesingleeﬀecteventchainsinglesentencetemporalityrelationship


pc3.8e-036.3e-036.3e-036.3e-036.3e-036.3e-036.3e-033.1e-033.1e-03


aerospace*8.0e-051.5e-018.2e-039.8e-026.4e-037.2e-026.3e-01*3.3e-103.1e-02agriculture*7.0e-04(domain contained less than 100 causal sentences)astronomy*4.1e-086.2e-021.0e-028.9e-012.7e-011.1e-012.4e-01*4.4e-053.0e-01automotive2.9e-01(domain contained less than 100 causal sentences)banking*1.9e-041.3e-015.3e-019.0e-022.8e-025.3e-012.6e-01*7.8e-064.4e-01data analytics*1.4e-053.4e-021.3e-022.3e-02*3.7e-031.3e-013.9e-013.6e-015.9e-01digital library9.3e-01(domain contained less than 100 causal sentences)digital society4.4e-03(domain contained less than 100 causal sentences)health*9.4e-041.4e-025.7e-017.9e-026.8e-016.3e-017.7e-017.0e-021.8e-01infrastructure*2.1e-065.0e-013.2e-014.1e-011.6e-015.0e-016.8e-016.1e-01*6.7e-05physics*2.1e-04(domain contained less than 100 causal sentences)smart city*8.4e-075.9e-02*2.0e-051.3e-023.5e-013.2e-01*2.3e-03*3.1e-053.9e-01sustainability*1.4e-14*1.2e-04*2.3e-048.7e-015.4e-011.4e-02*5.7e-033.5e-011.9e-01telecomm5.7e-012.2e-017.3e-015.2e-013.1e-011.8e-023.5e-021.0e-017.1e-01


of the sample. where the p-value for a given domain and category is lowerthan the bonferroni-corrected signiﬁcance level (denoted for each category aspc), the cell is preﬁxed with an asterisk. the chi-squared test of independencedoes not suggest to reject the null hypothesis for the categories single cause


and event chain , but the distribution of 4 out of the eligible 9 domains in


the category temporality are signiﬁcantly diﬀerent. we can conclude thatthe distribution of values in all categories is domain-independent to a certaindegree: while the complexity of causality is mostly domain-independent, thedistribution of temporality diﬀers signiﬁcantly for a about a third of the eligi-ble domains. a stratiﬁed analysis for rq 4c is reported in tab. 4a and showsconsiderable diﬀerences in the usage of cue phrases in the domains, but alsoa degree of overlap: the cue phrase if is among the ﬁve most frequent cuephrases in all domains, closely followed by the cue phrases when and where.the stratiﬁed frequencies align with the overall distribution reported in tab. 2and lead to the assumption, that the distribution of cue phrases is mostlydomain independent. when looking at the most precise cue phrases per do-main in tab. 4b and the least precise cue phrases per domain in tab. 4c, thecue phrases also reﬂect the ﬁndings from the overall distribution: precise cuephrases like if, when, and because as well as infrequent, but precise causativeverbs are equally represented in the domains just as imprecise cue phrases likefor or by. we conclude that despite slight domain-speciﬁc variations, the re-sults for rq 4c are also domain-independent1.


3.5 implications for causality detection and extraction


based on the results of our case study, we draw the following conclusions:causality is prevalent in requirements artifacts and therefore matters in re-


1 more extensive tables reporting on the frequency and precision of cue phrases in eligibledomains are included in the replication package.


causality in requirements artifacts: prevalence, detection, and impact17


table 4: distribution and precision of cue phrases in eligible domains


(a) relative frequency of cue phrases within one domain


most frequent2nd most frequent3rd most frequent4th most frequent5th most frequentdomain


aerospaceduring (8.5%)when (8.4%)if (7.5%)in order to (3.7%)after (3.0%)astronomyfor (10.2%)during (9.1%)allow (9.1%)in (5.7%)to (5.7%)bankingif (11.2%)to ensure (8.8%)once (7.2%)allow (5.6%)through (4.8%)data analyticsif (10.7%)when (9.4%)where (7.9%)for (5.2%)during (4.2%)healthwhen (11.5%)if (11.5%)during (10.5%)for (4.6%)after (3.8%)infrastructurewhere (16.5%)if (15.1%)to ensure (5.6%)for (5.3%)then (4.9%)smart cityin order to (10.7%)when (7.4%)if (7.1%)therefore (4.9%)that (4.4%)sustainabilitytherefore (8.6%)in order to (7.0%)if (5.9%)for (5.4%)where (4.3%)telecommif (8.7%)during (8.0%)in order to (6.0%)when (5.3%)in case of (4.7%)


(b) most precise cue phrases of each eligible domain


most precise2nd most precise3rd most precise4th most precisedomain


aerospaceimposes (100.0%)as far as (100.0%)result from (100.0%)in this case (100.0%)agriculturesince (100.0%)whose (100.0%)before (100.0%)when (100.0%)astronomyduring (100.0%)in the event of (100.0%)so that (100.0%)attain (100.0%)automotivewhen (100.0%)in order to (100.0%)therefore (100.0%)whose (100.0%)bankingin order to (100.0%)reduce (100.0%)will be required (100.0%)since (100.0%)data analyticsas long as (100.0%)increases (100.0%)unless (100.0%)so that (100.0%)digital libraryonly for (100.0%)cause (100.0%)because (100.0%)unless (100.0%)digital societyin order to (100.0%)if (100.0%)due to (100.0%)allows (100.0%)healthallows (100.0%)so that (100.0%)in the event of (100.0%)as a result (100.0%)infrastructurelead to (100.0%)prevent (100.0%)whose (100.0%)until (100.0%)physicsis needed (100.0%)after (100.0%)therefore (100.0%)when (100.0%)smart cityresult in (100.0%)to measure (100.0%)increase (100.0%)thereby (100.0%)sustainabilitywill require (100.0%)enables (100.0%)ensures (100.0%)because (100.0%)telecommallows (100.0%)enables (100.0%)during (100.0%)lead to (100.0%)


(c) least precise cue phrases of each eligible domain


least precise2nd least precise3rd least precise4th least precisedomain


aerospaceaccording to (14.3%)to get (20.0%)to mitigate (20.0%)based on (24.1%)agricultureon (26.1%)that (27.1%)at (28.2%)allows (33.3%)astronomyfrom (30.0%)by (31.0%)within (40.0%)where (50.0%)automotivewhich (10.0%)for (20.0%)on (24.2%)that (31.8%)bankingwhich (21.4%)to provide (25.0%)create (28.6%)by (28.8%)data analyticsto meet (16.7%)imply (20.0%)following (20.4%)but (20.5%)digital libraryallow (11.1%)for (27.6%)that (30.3%)with (31.8%)digital societyfor (45.8%)for this reason (50.0%)where (62.5%)allow (100.0%)healthin this (16.7%)around (20.0%)based on (22.2%)through (25.0%)infrastructurefollowing (18.2%)to provide (25.0%)on (41.3%)in (42.8%)physicswhile (33.3%)from (34.8%)in this (42.9%)for (43.6%)smart citywithin (11.1%)to perform (15.4%)who (15.4%)where (15.8%)sustainabilitywithin (3.8%)with (13.7%)to provide (14.3%)while (14.3%)telecommto provide (16.7%)which (19.4%)so that (20.0%)given (20.0%)


quirements engineering, which motivates the necessity of not only an eﬀectiveand reliable approach for the automatic detection and extraction of causal re-quirements, but also an investigation of the impact causality in requirementsartifacts has. the complexity of causal relations is conﬁned since they usu-ally consist of a single cause and eﬀect relationship in all observed, eligibledomains. however, for an approach that aims to extract the causal relation-ship to be applicable in practice, it needs to comprehend also more complexrelations containing at least two to three and at best an arbitrary number of


18frattini et al.


causes and eﬀects. understanding conjunctions, disjunctions, and negations isconsequently imperative to fully capture the relationships between causes andeﬀects and ensure the applicability of a detection and extraction approach.two-sentence causality and event chains occur only rarely. thus, both aspectscan initially be neglected in the development of the approaches and preservecoverage of more than 92 % of the analyzed sentences. the dominance of ex-plicit over implicit causal relations in the observed sentences simpliﬁes the de-tection and extraction of causality. the information about both causes andeﬀects is embedded directly in the sentences so that an approach requires lit-tle or no implicit knowledge. the analysis of the precision values reveals thatmost of the used cue phrases are ambiguous. consequently, automatic detec-tion and extraction methods require a deep understanding of language as thepresence of certain cue phrases is insuﬃcient as an indicator for causality. in-stead, a combination of the syntax and semantics of the sentence has to beconsidered to reliably detect causal relations.


3.6 threats to validity


internal validity a threat to the internal validity is the annotation process it-self as any annotation task is subjective to a certain degree. this is especiallyrelevant for more ambiguous categories like explicit , as implicit causality isdiﬃcult to determine. two mitigation strategies were performed to minimizethe bias of the annotators: first, we conducted a workshop prior to the an-notation process to ensure a common understanding of causality. second, weassessed the inter-rater agreement by using multiple metrics (cohen’s kappa,agreement score, and gwet’s ac1). however, it has to be noted that all cate-gories except causality are dependent on a sentence’s classiﬁcation regardingthat category, which may imply a confounding factor for the inter-rater agree-ment on the other categories. this manifests in the calculation of the inter-rater agreement, where all categories except causality are calculated basedon the 499 causal sentences. we argue however that the other categories are ir-relevant for non-causal sentences as they only refer to the causal relation con-tained by a sentence, hence this confounding factor is deemed minimal. apartfrom that, the inter-rater agreement is not domain-speciﬁc, which implies thatit is not possible to identify, whether certain domains caused more disagree-ment among the raters. we deem the general inter-rater agreement reportedin tab. 1 suﬃcient but recommend considering this aspect for replications andfuture studies intensifying the domain-dependent aspect of causality. further-more, restricting the manual detection of causal relations to a span of a maxi-mum of two sentences poses also a threat to internal validity, as the potentialexistence of causal relations that are spread across more than two sentencescan neither be conﬁrmed nor denied based on our investigation. we see thisthreat to be minimal as the relationship between one-sentence-causality andtwo-sentence-causality allows for the assumption, that the further elements ofa causal relation are spread apart, the more unlikely the existence of such a


causality in requirements artifacts: prevalence, detection, and impact19


causal relation is. extrapolating from the low number of sentences categorizedas two-sentence-causality gives us reason to assume that disregarding causalrelations spread across three sentences or more is negligible for this initial casestudy.


external validity to achieve reasonable generalizability, we selected require-ments documents from diﬀerent domains and years. as fig. 1 shows, our dataset covers a variety of domains, but the distribution of the sentences is im-balanced. the domains aerospace, data analytics, and smart city account fora large share in the data set (9,724 sentences), while the other 15 domainsare rather underrepresented. we mitigate this threat to validity by includinga domain-speciﬁc investigation reported in the scope of rq 6, which conﬁrmsthat the occurrence of causality is to a large degree domain-independent. fu-ture studies should however expand to more documents emerging from under-represented domains to allow a more general reﬂection upon diﬀerent aspectsof causality in requirements documents.


4 approach: detecting causal requirements


this section presents the implementation of our causal classiﬁer. to this end,we describe a variety of applied methods followed by a report of the resultsof our experiments, in which we compare the performance of the individualmethods and draw a conclusion in regards to applicability.


4.1 methods


rule-based approach instead of using a random classiﬁer as the baseline ap-proach, we involve simple regex expressions for causality detection. we iter-ate through all sentences in the test set and check if one of the phrases listedin tab. 2 is contained. in the positive case, the sentence is classiﬁed as causaland vice versa. as discussed in sect. 2, the classiﬁcation of a sentence as causalbased on the occurrence of a cue phrase – which the baseline approach repre-sents – is reasonable to assume.


machine learning-based approach as a second approach, we investigate theuse of supervised ml models that learn to predict causality based on the la-beled data set. speciﬁcally, we employ established binary classiﬁcation algo-rithms: naive bayes (nb), support vector machines (svm), random forest(rf), decision tree (dt), logistic regression (lr), ada boost (ab), andk-nearest neighbor (knn). to determine the best hyperparameters for eachbinary classiﬁer, we apply grid search, which ﬁts the model on every possi-ble combination of hyperparameters and selects the most performant. we usetwo diﬀerent methods as word embeddings: bag of words (bow) and termfrequency-inverse document frequency (tf-idf). in tab. 5 we report the


20frattini et al.


classiﬁcation results of each algorithm as well as the best combination of hy-perparameters.


deep learning-based approach with the rise of deep learning (dl), moreand more researchers are using dl models for natural language processing(nlp) tasks. in this context, the bidirectional encoder representations fromtransformers (bert) model [8] is prominent and has already been used forquestion answering and named entity recognition. bert is pre-trained on largecorpora and can therefore easily be ﬁne-tuned for any downstream task withoutthe need for much training data (transfer learning). in our paper, we makeuse of the ﬁne-tuning mechanism of bert and investigate to which extent itcan be used for causality detection of requirement sentences. first, we tokenizeeach sentence. bert requires input sequences with a ﬁxed length (maximum512 tokens). therefore, for sentences that are shorter than this ﬁxed length,padding tokens (pad) are inserted to adjust all sentences to the same length.other tokens, such as the classiﬁcation (cls) token, are also inserted in orderto provide further information of the sentence to the model. cls is the ﬁrsttoken in the sequence and represents the whole sentence (i.e., it is the pooledoutput of all tokens of a sentence). for our classiﬁcation task, we mainly usethis token because it stores the information of the whole sentence. we feed thepooled information into a single-layer feedforward neural network that usesa softmax layer, which calculates the probability that a sentence is causal ornot. we tune bert in three diﬀerent ways and investigate their performance:


– bertbase in the base variant, the sentences are tokenized as describedabove and put into the classiﬁer. to choose a suitable ﬁxed length forour input sequences, we analyzed the lengths of the sentences in our dataset. even with a ﬁxed length of 128 tokens, we cover more than 97 % ofthe sentences. sentences containing more tokens are shortened accordingly.since this is only a small amount, only a little information is lost. thus,we chose a ﬁxed length of 128 tokens instead of the maximum possible 512tokens to keep bert’s computational requirements to a minimum.


– bertpos studies have shown that the performance of nlp models canbe improved by providing explicit prior knowledge of syntactic informa-tion to the model [48]. therefore, we enrich the input sequence with syn-tactic information and feed it into bert. more speciﬁcally, we add thecorresponding part-of-speech (pos) tag to each token by using the spacynlp library [27]. one way to encode the input sequence with the corre-sponding pos tags is to concatenate each token embedding with a hot en-coded vector representing the pos tag. since the bert token embeddingsare high-dimensional, the impact of a single added feature (i.e., the postag) would be low. contrary, we hypothesize that the syntactic informa-tion has a higher impact if we annotate the input sentences directly withthe pos tags and then put the annotated sentences into bert. this wayof creating linguistically enriched input sequences has already proven tobe promising during the development of the nlpl word embeddings [10].fig. 5 shows how we incorporated the pos tags into the input sequence.


causality in requirements artifacts: prevalence, detection, and impact21


bertbase: if the process fails, an error message is shown.bertpos: if sconj the det process noun fails verb , punct an det er-ror noun message noun is aux shown verb . punctbertdep: if mark the det process nsubj fails advcl , punct an det error compoundmessage nsubjpass is auxpass shown root . punct


fig. 5: input sequences used for our diﬀerent bert ﬁne-tuning models. postags are marked blue and dep tags are marked orange.


by extending the input sequence, the ﬁxed length for the bert model hasto be adapted accordingly. after further analysis, a length of 384 tokensproved to be reasonable.


– bertdep similar to the previous ﬁne-tuning approach, we follow theidea of enriching the input sequence by linguistic features. instead of usingthe pos tags, we use the dependency (dep) tags (see fig. 5) of eachtoken. thus, we provide knowledge about the grammatical structure ofthe sentence to the classiﬁer. we hypothesize that this knowledge has apositive eﬀect on the model performance, as a causal relation is a speciﬁcgrammatical structure (e.g., it often contains an adverbial clause) and theclassiﬁer can learn causal speciﬁc patterns in the grammatical structure ofthe training instances. the ﬁxed token length was also increased to 384tokens.


4.2 evaluation procedure


our labeled data set is imbalanced as only 28.1 % are positive samples. toavoid the class imbalance problem, we apply random under sampling (seefig. 6). we randomly select sentences from the majority class and excludethem from the data set until a balanced distribution is achieved. our ﬁnal dataset consists of 8,430 sentences of which 4,215 are causal and the other 4,215are non-causal. we follow the idea of cross-validation and divide the data setinto a training, validation, and test set. the training set is used for ﬁtting thealgorithm, while the validation set is used to tune its parameters. the test setis utilized for the evaluation of the algorithm based on real-world unseen data.we opt for 10-fold cross-validation as a number of studies have shown that amodel that has been trained this way demonstrates low bias and variance [29].we use standard metrics for evaluating our approaches: accuracy, precision,recall, and f1 score [29]. since a single run of a k-fold cross-validation may re-sult in a noisy estimate of model performance, we repeat the cross-validationprocedure ﬁve times and average the scores from all repetitions (see tab. 5).when interpreting the metrics, it is important to consider which misclassiﬁca-tion (false negative or false positive) matters most, respectively causes thehighest costs. since causality detection is supposed to be the ﬁrst step towardsautomatic causality extraction, we favor recall over precision. a high recallcorresponds to a greater degree of automation of causality extraction becauseit is easier for users to discard false positives than to manually detect false


22frattini et al.


labeled data set 


1234k…


training settest set


balanced data set 


random under


sampling


training foldsvalidation fold


dl 


approaches


ml 


approaches


add pos and 


dep tagstraining


trained models


rule-based


approach


tune hyperparameters / 


adjust model weights


4,215 causal4,215 not causal


evaluate


generalization


best performing 


model (cira)


4,215 causal10,786 not causal


fig. 6: implementation and evaluation procedure of our binary classiﬁer


negatives. consequently, we seek high recall to minimize the risk of missedcausal sentences and acceptable precision to ensure that users are not over-whelmed by false positives.


4.3 experimental results


tab. 5 demonstrates the inability of the rule-based baseline approach to dis-tinguish between causal (f1 score: 66 %) and non-casual (f1 score: 64 %)sentences. this coincides with our observation from the ﬁrst case study thatclassifying sentences as causal or non-causal based on the occurrence of cuephrases is not suitable for causality detection. in comparison, most ml-basedapproaches (except knn and dt) show a better performance. the best per-formance in this category is achieved by rf with an accuracy of 78 % (gainof 13 % compared to baseline approach). the overall best classiﬁcation re-sults are achieved by our dl-based approaches. all three variants were trainedwith the hyperparameters recommended by devlin et al. [8]. even the vanillabertbase model shows a great performance in both classes (f1 score ≥80 % for causal and non-causal). interestingly, enriching the input sequenceswith syntactic information did not result in a signiﬁcant performance boost.bertpos even has a slightly worse accuracy value of 78 % (diﬀerence of2 % compared to bertbase). an improvement of the performance can be ob-served in the case of bertdep, which has the best f1 score for both classesamong all the other approaches and also achieves the highest accuracy valueof 82 %. compared to the rule-based and ml-based approaches, bertdepyields an average gain of 11.06 % in macro-recall and 11.43 % in macro-precision. interesting is a comparison with bertbase. bertdep shows bet-ter values across all metrics, but the diﬀerence is only marginal. this indicatesthat bertbase already has a deep language understanding due to its exten-sive pre-training and therefore can be tuned well for causality detection with-out much further input. however, over all ﬁve runs, the use of the dependencytags shows a small but not negligible performance gain - especially regarding


causality in requirements artifacts: prevalence, detection, and impact23


table 5: recall, precision, f1 scores (per class) and accuracy. we report theaveraged scores over ﬁve repetitions. best results for each metric are high-lighted in bold.


causal (support: 435)not causal (support: 408)best hyperparametersrecallprecisionf1recallprecisionf1accuracyrule based-0.650.660.660.650.630.640.65


ml based


nbalpha: 1, ﬁt prior: true,embed: bow0.710.70.710.680.690.690.7


svmc: 50, gamma: 0.001,kernel: rbf, embed: bow0.680.80.730.820.710.760.75


rfcriterion: entropy, max features: auto,n estimators: 500, embed: bow0.720.820.770.840.740.790.78


dtcriterion: gini, max features: auto,splitter: random, embed: tf-idf0.650.680.660.670.650.660.66


lrc: 1, solver: liblinear,embed: tf-idf0.710.780.740.790.720.750.75


abalgorithm: samme.r, n estimators: 200,embed: bow0.670.780.720.80.70.750.74


knnalgorithm: ball tree, n neighbors: 20,weights: distance, embed: tf-idf0.610.680.640.70.630.660.65


dl basedbertbasebatch size: 16, learning rate: 2e-05,weight decay: 0.01, optimizer: adamw


0.830.800.820.780.820.800.81bertpos0.820.760.790.710.830.770.78bertdep (cira)0.850.810.830.790.840.810.82


our main decision criterion: the recall value (85 % for causal and 79 % fornon-causal). therefore, we choose bertdep as our ﬁnal approach (cira).


5 case study 2: eﬀects of causality


after discussing ﬁrst empirical evidence on the extent and complexity to whichcausality is used in nl requirements in our ﬁrst case study (c1) and construct-ing a reasonably eﬀective approach for automatic causality detection (c2), weaim to corroborate the relevance of causality for requirements in a second casestudy (c3). here, we investigate the impact of causal relations on the featuresof requirements, where we consider features to be observable attributes of indi-vidual requirements (e.g., their lead-time). this investigation emerges from anongoing academia-industry collaboration in a larger context. our exploratorycase study has two goals: ﬁrst, we aim to demonstrate an independent use caseof the automatic causality detection approach. while automatic causality de-tection as presented in sect. 4 can be used as a precursor to automatic causal-ity extraction and therefore as one step in a pipeline towards automatic testcase generation, we explore considering the occurrence of causality as an aspectof requirements quality and consequently automatic causality detection as ametric to estimate requirements quality. an eﬀective tool-supported approachfor detecting causality in nl requirements allows exploring the eligibility ofcausality as an aspect of requirements quality. gathering the ﬁrst empiricalevidence towards this is the second goal of this exploratory case study. firstempirical evidence can be gathered by investigating the correlation betweenthe occurrence of causality in requirements and features of these requirements.


24frattini et al.


5.1 research questions


we are interested in the impact that the occurrence of causal relations in nat-ural language requirements has on important features of these requirements.empirical evidence for an impact of causality on these features would allowthe assumption that the use of causality in a nl requirement contributes tothe requirement’s quality. while a deﬁnite connection cannot be determinedbased on a correlation analysis alone, this exploratory case study rather aimstowards providing ﬁrst insights into the feasibility of using causality as a qual-ity aspect for requirements and opening up a more detailed discussion regard-ing speciﬁc features. we select the following features for our analysis:


– lead-time: the time from the inception until the completion of a require-ment.


– consolidated state: the type of ﬁnal state in which the requirement endsin.


– volatility: number of state changes which the requirement undergoes.the selection of attributes is inspired by research with comparable objectives,which used lead-time and the resulting consolidated state [41] as well as thevolatility [51] of requirements as dependent variables to estimate the impact ofrequirements attributes on the downstream development process. a data seteligible for this evaluation needs to provide information in form of a state log,where each entry in the log documents the author, timestamp, and state code.the state codes represent the diﬀerent states which a requirement traversesduring its life cycle from its inception to its completion. the lead-time conse-quently constitutes the time delta between the ﬁrst and the last state log entry.the consolidated state is the ﬁnal state of the state log. the volatility denotesthe number of entries in the state log, as it directly correlates with the numberof additional development cycles the requirement has to traverse (e.g., by beingpushed back to earlier states when repeating one development cycle). we wantto investigate whether a statistically signiﬁcant diﬀerence can be determinedin the distribution of lead-time, consolidated state, and volatility between re-quirements that use causal relations versus requirements that do not. to thisextent, we aim at providing answers to the following research questions (rq):


– rq 7: does the use of causality in an nl requirement correlate with itslead-time?


– rq 8: does the use of causality in an nl requirement correlate with itsconsolidated state?


– rq 9: does the use of causality in an nl requirement correlate with itsvolatility?these attributes have been chosen as an eligible representation of the require-ments’ comprehensibility and degree of ambiguity. as elaborated in earliersections, we hypothesize that the clear semantic structure of a causal relationpromotes comprehensibility and mitigates the ambiguity of requirements. thiswould result in shorter lead times, a greater likelihood of a successful outcome,and less volatility, as the requirement has to undergo fewer iterations in thedevelopment life-cycle.


causality in requirements artifacts: prevalence, detection, and impact25


table 6: features of the data set


featuredescriptiondatatype


idunique identiﬁer of the requirementnumeric


descriptiontextual description containing a varying amount ofnl sentences


text


state loghistory of state changescategorical list


date of cre-ation


inception date of the requirementdate


5.2 study design


study objects the study is performed on a data set for an industrial, propri-etary project. the owning, multi-national case company develops and globallydistributes software-intensive products for a b2c market. the number of en-gineers involved with the product line of the data set in question varied from1000 to 4000 worldwide. the original data set, pre-processed by olsson etal. [41] contains 4446 requirements collected in 20162. the data set has beenchosen because it contains the aforementioned features necessary for the eval-uation, other than the data sets used for the ﬁrst case study: most of the re-quirements in the data set contain a state log documenting the requirement’slife cycle from its inception as a new feature (nf) to its ﬁnal state as ei-ther execution completed (ec) or discarded (d). the newly created require-ments undergo the initial triage in a state called m0. next, upon consideredviable and suﬃciently justiﬁed, the requirement candidates are prioritized ina project prioritization state (similar to backlog prioritization), called m1. fi-nally, the prioritized requirements are hand-shaken with the developer teamsin a state called m2 [18]. when a requirement is unclear at the m2 state, itis pushed back to m1 for re-prioritization. similarly, a requirement is pushedback to m0 when questions and uncertainties arise during requirements pri-oritization. these backward transitions unusually increase the lead-time. thefeatures relevant for this study are described in tab. 6. further attributes weregenerated based on the existing features:


– sentences: the number of sentences occurring in the description ﬁeld iscounted via sentence tokenization.


– causal relations: the number of causal sentences in the descriptionﬁeld is counted by applying the cira-tool presented in sect. 4 to eachsentence.


– lead-time: the lead-time is calculated as the time frame between theﬁrst and the last entry of the state log.


– volatility: number of decisions counted as the number of entries in thestate logthe data set of 4446 requirements was further pre-processed to serve the ap-plication in this second case study. three additional ﬁlters have been applied:(1) requirements, for which the state log did not exist, were discarded. (2) re-


2 the proprietary data set cannot be disclosed at the time of submission as it containscritical company information.


26frattini et al.


table 7: pre-processing steps


idfilterremovedremaining


1missing consolidated state log1764270


2speciﬁc, invalid author1854085


3singular state log entry4543631


total8153631


quirements with a state log authored by exactly one, speciﬁc individual, werediscarded. the entries to these state logs were due to database migrations anddo not contain actual information on the requirements life cycle. (3) require-ments with only one entry in the state log were discarded. these requirementsdo not allow calculating a meaningful lead-time. in total, 815 requirementswere discarded due to the pre-processing, leaving 3631 requirements for theanalysis. tab. 7 lists further details on the ﬁltering process.


data analysis the research questions can be translated into statistically ver-iﬁable (i.e., refutable) hypotheses. we therefore formulate the following nullhypotheses:


– h10: requirements containing diﬀerent amounts of causality have the samedistribution of lead-time.


– h20: requirements containing diﬀerent amounts of causality have the samedistribution of consolidated states.


– h30: requirements containing diﬀerent amounts of causality have the samedistribution of volatility.in all hypotheses the input variable contained amounts of causality is testedon two levels of granularity: (g1) binary (containing at least one causal sen-tence vs. containing no causal sentence) and (g2) in batches (ranges of num-ber of causal sentences). furthermore, granularity g1 is extended to the thirdlevel of granularity (g3) where the data set is split into three subsets con-taining requirements of diﬀerent sentence sizes. the distribution of causal sen-tences according to the diﬀerent levels of granularity is given in tab. 8 andtab. 9. where the binary granularity g1 serves to investigate the general ef-fect of causality and the batch granularity g2 reﬁnes this relation, the ex-tended granularity g3 normalizes the eﬀect according to requirement size. allhypotheses are reported using descriptive statistics and evaluated using infer-ential statistics. the hypothesis of independence is calculated using the mann-whitney u test on the binary level of granularity (g1 and g3) for the inter-val scale variable of lead-time and volatility, and using the chi-square test forthe categorical variable of consolidated state. for batch granularity g2 thekruskal-wallis test is used [19]. all statistical tests of independence are eval-uated with a signiﬁcance level α = 0.05. where a statistical tests suggests toreject the null hypothesis of independence, the eﬀect size of the correlation isquantiﬁed using cohen’s d for binary granularities g1 and g3 [47] and eta-squared for batch granularity g2 [7]. these measures allow categorizing themagnitude of the correlation eﬀect.


causality in requirements artifacts: prevalence, detection, and impact27


table 8: distribution of sentences according to granularity g1 and g2


ncausalnreq


non-causal[0]1000


causal


[1, 3]2059


[4, 6]457


[7, 9]96


[10, 12]15


[13, 15]2


[16, 18]1


[19, 21]1


total[0, 21]3631


table 9: distribution of sentences according to granularity g1 and g3


nsentences[1, 3][4, 7][8, max][1,max]


causal54293311562631


non-causal5143311751000


total1056124413313631


table 10: p- and cohen’s d value for evaluating the respective null-hypothesiswith the given granularity. cells preﬁxed with * indicate where the null-hypothesis has been rejected (given signiﬁcance level α = 0.05).


hypothesismeasureg1g2g3


[1, 3][4, 7][8, max]


h10p-value*0.0004*0.00820.3434*0.0008*0.0084eﬀect size0.05140.0010-0.11810.1496


h20p-value0.84970.06680.13680.14560.7661eﬀect size-----


h30p-value*0.01050.08560.2184*0.00110.1261eﬀect size0.0742--0.1843-


5.3 study results


all study results are reported in tab. 10 and explained in further detail in thefollowing sections.


correlation between causality and lead-time fig. 7a displays the distributionof lead-time in the two binary groups in the form of violin plots and indicatesthat the lead-time of requirements containing at least one causal sentence is onaverage lower than the lead-time of requirements without any causality. themann-whitney u test of independence yields a p-value of 0.00038 far below thesigniﬁcance level α = 0.05, rejecting the null hypothesis of similar distributionand corroborating the found diﬀerence. cohen’s d quantifying the eﬀect sizeyields 0.0514, which categorizes the eﬀect size of the correlation as small. forgranularity g2 only batches containing more than 10 sentences were included,which leads to discarding all batches containing more than 12 causal sentences


28frattini et al.


containing


no causality


containing


causality


0


200


400


600


800


1000


lead time in days


(a) binary granularity g1


[0][1, 3][4, 6][7, 9][10, 12]


number of causal sentences


in the requirement


0


200


400


600


800


1000


lead time in days


(b) batch granularity g2


fig. 7: distribution of lead-time (h10)


containing


no causality


containing


causality


0


200


400


600


800


1000


lead time in days


(a) small requirements


containing


no causality


containing


causality


0


200


400


600


800


1000


lead time in days


(b) medium requirements


containing


no causality


containing


causality


0


200


400


600


800


1000


lead time in days


(c) large requirements


fig. 8: distribution of lead-time for binary granularity split by the size ofrequirements (h10)


due to statistical insigniﬁcance. the results of evaluating h10 on a ﬁner level ofgranularity g2 shows that the increased usage of causal sentences has a positiveeﬀect on reducing the average lead-time up until the point of using 10 or morecausal sentences as shown in fig. 7b. the kruskal-wallis test of independencesuggests to reject the null hypothesis of similar distribution with a p-value of0.0082, but the eta-squared value of 0.0010 categorizes the correlation as neg-ligible [7]. evaluating the diﬀerence in distribution on granularity g3 revealsthat the size of the requirement is a contributing factor to the correlation be-tween the occurrence of causality and the lead-time: while the use of causalityin small requirements has a negative eﬀect on the lead-time, the opposite is ob-servable for medium and large requirements, as illustrated in fig. 8. the nullhypothesis of independence is accepted for small requirements with p = 0.34and rejected for medium and large requirements with p = 0.0008 and p = 0.008


correlation between causality and consolidated state the data set uses 20 cat-egories for the variable consolidated state, of which most represent intermedi-ate states. the data set of 3442 requirements is ﬁltered for all requirementsin ﬁnal states, which are execution completed (ec) and discarded (d), respec-


causality in requirements artifacts: prevalence, detection, and impact29


contains no


causality


containscausality


0


20


40


60


80


100


requirements in consolidated state


51.6%50.8%


48.4%49.2%


ecd


(a) binary granularity g1


[0][1, 3][4, 6][7, 9][10, 12]


number of causal sentences in the requirement


0


20


40


60


80


100


requirements in consolidated state


51.6%49.3%52.5%


76%


66.7%


48.4%50.7%47.5%


24%


33.3%


ecd


(b) batch granularity g2


fig. 9: distribution of ﬁltered consolidated states (h20)


contains no


causality


containscausality


0


20


40


60


80


100


requirements in consolidated state


46%


37.8%


54%


62.2%


ecd


(a) small requirements


contains no


causality


containscausality


0


20


40


60


80


100


requirements in consolidated state


57.8%


49.1%


42.2%


50.9%


ecd


(b) medium requirements


contains no


causality


containscausality


0


20


40


60


80


100


requirements in consolidated state


56.7%59.6%


43.3%40.4%


ecd


(c) large requirements


fig. 10: distribution of ﬁltered consolidated for binary granularity split by thesize of requirements (h20)


tively positive and negative ﬁnal state. only the 1157 requirements in thesetwo ﬁnal states (ec: 591, d: 566) were considered for this evaluation. fig. 9aillustrates the distribution of consolidated states on binary granularity g1.the chi-square test of independence yields a p-value of 0.85 and does thereforenot allow to reject the null hypothesis. increasing the granularity to batchesas displayed in fig. 9b suggests a positive trend in the correlation between theoccurrence of causality and a successful consolidated state, but the kruskal-wallis test does not allow to reject the null hypothesis of similar distributionwith a p-value of 0.067. at granularity g3, the consolidated states of require-ments of diﬀerent sizes correlate negatively with the occurrence of causalityfor small and medium requirements with only a slight positive correlation forlarge requirements, as seen in fig. 10. the null hypothesis of independence


30frattini et al.


contains no


causality


containscausality


5


10


15


20


25


number of state changes


(a) binary granularity g1


[0][1, 3][4, 6][7, 9][10, 12]


number of causal sentences in the requirement


5


10


15


20


25


number of state changes


(b) batch granularity g2


fig. 11: distribution of volatility (h30)


correlation between causality and volatility fig. 11a displays the distributionof the volatility metric in the two binary groups as violin plots. overall, aslight correlation between the occurrence of causality and the volatility of arequirement can be observed, which is corroborated by the rejected test ofindependence with a p-value of 0.01 and an eﬀect size of 0.07. investigating thiseﬀect at batch granularity g2 in fig. 11b, however, reveals that this positivecorrelation is constrained to requirements with a low occurrence of causalsentences, where requirements with many causal sentences show a trade-oﬀofhigher average volatility despite a smaller overall range of volatility values. thekruskal-wallis test of independence does not allow to reject the null-hypothesisof similar distribution with a p-value of 0.086. investigating the correlationat granularity g3 as displayed in fig. 12, this trade-oﬀis again visible andemphasizes the positive correlation between the occurrence of causality and thevolatility of requirements for medium-sized requirements. this is conﬁrmed bythe independence tests, where the null hypothesis can be rejected for mediumrequirements with a p-value of 0.001 and eﬀect size of 0.18, but not for smallor large requirements with p-values of 0.22 and 0.13 respectively.


5.4 implications


impact of causality the results of the second case study show an already ex-isting positive correlation between the occurrence of causal relations and thefeatures of requirements artifacts. these results motivate further, in-depth in-vestigations corroborating the relationship between the occurrence of causal-ity and features of these requirements, suggesting the feasibility of consider-ing causality as an aspect of requirements quality. both the direct insights andthe consequent hypothesis for future research are discussed in more detail inthe following paragraphs.


causality in requirements artifacts: prevalence, detection, and impact31


contains no


causality


containscausality


5


10


15


20


number of state changes


(a) small requirements


contains no


causality


containscausality


5


10


15


20


25


number of state changes


(b) medium requirements


contains no


causality


containscausality


5


10


15


20


number of state changes


(c) large requirements


fig. 12: distribution of volatility for binary granularity split by the size ofrequirements (h30)


answer to rq 7: the use of causality correlates slightly with smallerlead-times of requirements and therefore suggests considering causality as animpact factor when estimating the life-cycle of a requirement. a consequenthypothesis of this correlation is that the strict semantic structure of the rela-tion causes an eﬀect on the comprehensibility of a requirement, which makesit easier to translate into downstream artifacts like code or test cases.answer to rq 8: the use of causality does not correlate with the con-solidated state of requirements. it is safe to assume that the occurrence ofcausality does not impact the life-cycle of requirements regarding its consoli-dated state statistically signiﬁcant in comparison to other factors.answer to rq 9: the use of causality correlates slightly with smallervolatility of requirements. comparably to rq 7, the hypothesis that the se-mantic structure of the relation causes an eﬀect on the understandability of arequirement, which in turn requires fewer decisions due to being less ambigu-ous, can be derived from the correlation analysis. we conclude that the rela-tionship between the use of causality in nl requirements and lead-time as wellas the volatility of requirements is worth for further, more thorough investiga-tion: the slight correlation supports the feasibility of considering causality asan aspect of requirements quality.


applicability of automatic causality detection the initial, exploratory inves-tigation of this phenomenon demonstrates a possible use case of automaticcausality detection as part of a quality metric. the small extent of the corre-lations and their low eﬀect size according to the applied measures emphasizethat the occurrence of causality is deﬁnitely not the only or most impactful,but certainly a considerable factor for the features of requirements. consider-ing the detection of causality with the approach presented in this research en-deavor as a complement to other requirements quality frameworks such as forexample requirements smells [12] might beneﬁt the reliability of these qualitymetrics by taking positive eﬀects on requirements into account. future stud-ies need to investigate this claim in further detail.


32frattini et al.


5.5 threats to validity


external validity the generalizability of results cannot be claimed based onthe exploratory case study on one data set. further data sets are necessary tobe investigated and compared to compensate for context factors like the sizeand domain of the company, the utilized development process, techniques em-ployed in the requirements engineering phase, as well as applied technologies.however, the analyzed data-set represents ﬁve years of product development(between 2010 and 2015) with 41 products and 36 software releases. there-fore, the heterogeneity of authors and editors of requirements is high.


internal validity to ensure that the correlation between the occurrence ofcausality and the lead-time of requirements is indeed causal and not con-founded, further qualitative analysis beyond the data recorded in the respec-tive data set must be performed. the impact of causality on comprehensibilityin contrast to other factors of ambiguity has to be addressed in future stud-ies of qualitative nature. apart from that, another possible threat to validityis that the analyzed data could contain incorrect information, caused for ex-ample by a lack of diligence when providing certain information for a require-ment. since this data set is based on real project data and has been fosteredover the course of ﬁve years in an industrial setting the threat is consideredlow, but still worth mentioning.


6 related work


6.1 application of causality detection


as indicated in sect. 2, many disciplines have already dealt with the notion ofcausality and explored use cases for its application. one of the earliest appli-cations of causality detection includes the utilization of causality for questionanswering. girju et al. [21] propose an approach using lexico-syntactic pat-terns within one sentence or two adjacent sentences, where the patterns con-sist of two noun phrases (np) connected with a causative verb (vp) in thefollowing structure:< np1verbnp2 >(4)


the patterns were built by traversing wordnet concepts for noun phrasesthat are connected by a cause-to-relationship, which is explicitly annotatedin the wordnet corpus. subsequently, from a large nl corpus, all verbs con-necting these causally related noun phrase pairs were extracted as causation-verbs. based on this information and further semantic features from wordnet,the lexico-syntactic patterns detecting causal relations were created. chang etal. [5] expand on this concept by taking into account conceptual pair probabil-ity and cue phrase probability as additional indicators for the classiﬁcation ofa causal relation. the focus on extracting causal relationships to automaticallyanswer why-questions is expanded to the inter-sentential level by pechsiri et


causality in requirements artifacts: prevalence, detection, and impact33


al. [42], who utilize the coexistence of causative and eﬀective verbs as indica-tors for causal relationships. other early approaches are rooted in the medicaldomain, where relationships between symptoms and diseases are commonlyexpressed in natural language sentences utilizing causality: khoo et al. [30] ex-tract causal knowledge from a medical database using graphical patterns. theroles and attributes of a causal situation are structured in a three-layer tem-plate, which constitutes the framework for manually elicited patterns. morerecent approaches like the one proposed by doan et al. [9] utilize pos tags anddependency parse trees to identify causal relations based on a manually gener-ated set of patterns from a large data set of tweets. in the ﬁeld of economics,causality detection has been applied to improve the reasoning about market-related relationships. early approaches include chan et al. [4] utilizing a hi-erarchy of manually generated semantic, sentence, and consequence and rea-son templates. other approaches like proposed by inui et al. [28], which alsoextract causal relations from newspapers, base their causality detection algo-rithm on the occurrence of cue phrases. the typology deﬁned in the courseof this research classiﬁes causal relations with respect to their arguments’ vo-litionality, where the volitionality of an event distinguishes an action from astate of aﬀairs. the resulting binary combinations of events of diﬀerent vo-litionality constitute the four relationships cause, eﬀect, precond, and means.recent work by xu et al. [56] acknowledges the lack of focus regarding label-ing and extraction methods in the area of causality extraction and contributesby summarizing and evaluating existing causality data sets. further applica-tions of causality detection include extrapolating causal relations based on se-mantic relations between nouns [26], eﬀectively increasing the domain of rea-soning based on causal relationships.


6.2 causality in requirements engineering


to the best of our knowledge, we are the ﬁrst to focus on causality from theperspective of requirements engineering. in our previously published papers,we motivated why the re community should engage with causality [15] andprovide empirical evidence for the relevance of causality in requirement docu-ments as well as further insights into its form and complexity [14]. the latterwork is extended in the manuscript at hand with an additional, exploratoryinvestigation of the implications of the use of causality in requirements arti-facts. detecting causality in natural language has been investigated by sev-eral studies which usually belong to one of two categories according to asgharet al. [1]: early approaches [30,55] use handcrafted, lexico-syntactic patternsto identify causal sentences. these approaches are highly dependent on themanually created patterns and show weak performance, inhibiting an eﬀectiveapplication in practice as shown in our comparison of algorithms in sect. 4.opposed to pattern-matching are feature-based classiﬁcation methods: recentpapers apply neural networks and exploit – similarly to our approach – thetransfer learning capability of bert [31]. however, we see a number of prob-


34frattini et al.


lems with these papers regarding the realization of our described re use cases:first, neither the code nor a demonstration is published, making it diﬃcult toreproduce the results and test the performance on data from the re domain.second, they train and evaluate their approaches on strongly unbalanced datasets with causal to non-causal ratios of 1:2 and 1:3, but only report the macro-recall and macro-precision values and not the metrics per class. thus, it isnot clear whether the classiﬁer has a bias towards the majority class or not.


7 conclusions and future work


the behavior of systems is often speciﬁed in terms of causal relations in naturallanguage requirements. eﬃciently extracting this causal information would al-low for eﬀective support of downstream activities that rely on such causal rela-tions, such as the tool-supported derivation of test cases and further activitiesthat need to reason about requirement dependencies [15]. however, contem-porary methods still fail to extract causality with reasonable performance [1].therefore, we have argued for the need for a novel method for causality ex-traction and closed this gap with the contributions in this manuscript. we un-derstand causality extraction as a two-step problem: first, we need to detectif requirements have causal properties. second, we need to comprehend andextract their causal relations. at present, however, we lack knowledge aboutthe form and complexity of causality in requirements, which is needed to de-velop suitable approaches for these two problems. in this manuscript, we re-ported on how we addressed this research gap by contributing: (c 1) an ex-ploratory case study with 14,983 sentences from 53 requirements documentsoriginating from 18 diﬀerent domains. we found that causality is a widely usedlinguistic pattern to describe system functionalities and that it mainly occursin explicit, marked form. (c 2) cira as an approach for the automatic de-tection of causality in requirements documents. this constitutes the ﬁrst steptowards causality extraction from nl requirements. we empirically evaluateour approach and achieve a macro-f1 score of 82 % on real-world data. (c 3)a demonstration of a possible use case of the automatic causality detectionapproach in a correlation analysis between the occurrence of causality and thelife-cycle features of a requirement. (c 4) finally, by following the open sci-ence norms and principles established in the empirical software engineering re-search community [38], we have further disclosed our entire source code, tool,and annotated data set within the limitations of existing non-disclosure agree-ments in order to actively support the research community working on sameor similar problems and further facilitate independent replications.two further research directions are, in our opinion, worth being mentionedhere: first, extending the ﬁrst case study and analyzing the sentences fromthe requirements documents in a more granular way by categorizing them –e.g., in functional and non-functional requirements – would enrich our currentinsight into causality in requirements documents in general with further in-sights into causality in speciﬁc requirement categories. this includes investi-


causality in requirements artifacts: prevalence, detection, and impact35


gating the particularities of speciﬁc domains, for example to explain the dif-ference in cue phrase precision. second, tackling the second of the two ear-lier mentioned sub-problems – the actual extraction of causal relations fromcausal sentences – will provide the necessary foundation to enable the varioususe cases. we are currently enhancing our previous approaches [16,17] withthe insights gained from this study and cordially invite the re community tojoin the endeavor. building on the second case study presented in sect. 5, fu-ture studies may continue exploring the relationship between the occurrenceof causality and features of requirements. extending the automatic causalitydetection approach beyond the current intra-sentential limitations may for ex-ample enable to investigate the relationship between requirements’ dependen-cies and features of requirements.


acknowledgements we would like to acknowledge that this work was supported, in parts,of technology. further, we thank yannick debes and michael dorner for stimulating dis-cussions and their valuable feedback on earlier versions of this work.

