
combining data analytics with team feedback to improvethe estimation process in agile software development


antonio vetr`o∗, rupert d¨urre†, marco conoscenti‡


daniel m´endez fern´andez§, magne jørgensen¶


abstract. we apply a mixed research method to improve the user stories es-timation process in a german company following agile software development. wecombine software project data analytics with elicitation of teams’ feedback, identifyroot causes for wrong estimates and propose an improved version of the estimationprocess. three major changes are adopted in the new process: a shorter non numer-ical scale for story points, an analogy-based estimation process, and retrospectivesanalyses on the accuracy of previous sprints estimates. the new estimation processis applied on a new project, and an improvement of estimates accuracy from 10% to45% is observed.


keywords: agile estimation, data analytics, process improvement


1.introduction and motivations


software process improvement [8] refers to the set of activities that aim to improve theprocesses, tools and activities of software development and make the whole softwareproject more successful. project planning is a critical activity for software develop-ment, being studied in the scientiﬁc literature as a key aspect for the success of asoftware project (e.g., see[12],[19], [4], [14]), also in agile software development(e.g.,[20]).in scrum, for example, it is very important to make accurate eﬀortestimation in the sprint planning phase [2]: in fact, the estimation of user stories 1


∗nexa center for internet & society, dauin, politecnico di torino, antonio.vetro@polito.it†netlight consulting, rupert@duerre.de‡nexa center for internet & society, dauin, politecnico di torino, marco.conoscenti@polito.it§technische universit¨at m¨unchen, daniel.mendez@tum.de¶simula metropolitan, magnej@simula.no1a user story is a small, independent feature that deliver value [11]


f o u n d a t i o n s  o f  c o m p u t i n g  a n d  d e c i s i o n  s c i e n c e svol. 43(2018)no. 4


issn 0867-6356


e-issn 2300-3405doi: 10.1515/fcds-2018-0016


are then used throughout the scrum process, from selection of the user stories un-til updating the burn-down chart. user stories estimates can incur in two types oferroneous predictions: overestimation, where the estimated eﬀort is higher than theactual eﬀort needed, and underestimations, where the estimation is lower than theactual work needed. the impact of overestimation could be diﬀerent depending onthe type [13, p. 1]: for example, overestimations might lead to a reduced productivityrate [15], since the development team expands “the work so as to ﬁll the time avail-able for its completion” [16]. furthermore, overestimations may result in the beliefthat the development of a feature or a product in general is not beneﬁcial and, as aconsequence, it will be erroneously rejected. another risk of overestimations is thatnew opportunities to undertake new projects might be overlooked due to the beliefthat there is no capacity available. [13, p. 1]. whereas accurate estimates may in-crease the productivity, large underestimations cause a lower quality of the productdue to the resulting time pressure. [9, p. 27]. moreover, underestimations might havedetrimental eﬀects on the project management, e.g. a wrong plan of the staﬃng of adevelopment team or a wrong allocation of resources. these eﬀects are often hard tohandle: for example it takes time and education to render the added staﬀbeneﬁcialand productive [13, p. 1].in this work we aim at contributing to the understanding of causes of wrong es-timates in agile software development, and tested an improvement proposal targetedto a german software company which develops web applications with agile method-ologies: the improvement methodology was based on software project data analyticsand project team feedback. we collected quantitative information from the estima-tion process in four development projects, we analyzed them and involved the projectteams in the interpretation of analysis results: we elicited explanations in meetingsin which the quantitative results were visually summarized to them. the collectedfeedback allowed us a deep understanding of the causes of wrong estimates and, onthe base of this knowledge, to propose three major changes in the estimation process:the use of a shorter and non-numerical scale for story points; an analogy-based mech-anism for estimating new user stories; the introduction of retrospective meetings forretrieving lessons learned from the analysis of estimates accuracy in previous sprints.the new estimation process was applied on a ﬁfth project, and we could observe animprovement of estimates accuracy from 10% to 45% with respect to the previousfour analyzed projects.our main contribution is an improvement methodology to study estimation issuesin agile software development projects. we also provide -on an online appendix- aproject characterization schema that should serve as a guide for replications of thisstudy in other contexts.the remainder of the paper is structured as follows: we enunciate our study goaland research questions in section 2, followed by metrics and measurement method-ology in section 3 and context description in section 4. then we report results insection 5 and discuss them in section 6. the new estimation process is introduced insection 7, the results of tis applications reported in section 8 and discussed in section9. we conclude the paper with the analysis of the study limitations and indication offurther work in section 10. we conclude with a short summary (section 11).


306


2.study goal and research questions


the goal of our study is to improve the estimation process in an agile software de-velopment project. table 1 shows a structured presentation of the goal according tothe goal-question-metric template [1]. in relation to the goal, we deﬁne six researchquestions.


study goalobjectofstudy


eﬀort estimations


purposeimprove


focusestimation process


stakeholderdevelopment teams and products owners


context fac-tors


software development company developingweb applications with agile methods


table 1. structured presentation of the study goal


the ﬁrst two questions investigates the presence of trends in the estimates over thecourse of the projects: if present, trends have a systematic impact on the accuracy ofestimations, that should be taken into account when interpreting the causes of sucherrors.


rq1: are estimates getting more similar during the projects?this re-search question investigates whether the range of story points used during the sprintsis similar throughout the course of the project or not. 2.


rq2: are estimates getting smaller or bigger during the projects?theresearch question investigates whether estimates have a tendency to increase or de-crease over the course of a project. this could be consequence of the increasing ordecreasing complexity of user stories in the backlog (e.g., bigger user stories in thebeginning, and smaller towards the end), or could reveal a tendency of the team insystematically underestimating or overestimating user stories with the progress of theproject. since this question only considers the estimated eﬀort assigned to a userstory and not the actual eﬀort needed for its implementation, the results from thisresearch question should be interpreted in light of the results of the following rqs,which involve the actual implementation eﬀort.


the next research questions involve the actual implementation eﬀort of the userstories, which is necessary to: compute the accuracy of the estimates (rq3); under-stand whether the relative value of a story point is constant (rq4); investigate on


2a special case occur when group dynamics lead people to estimate in the middle to avoid ex-plaining their estimates (especially the lowest and highest), which is required in planning poker incase estimates diﬀer consistently: this is a case where group dynamic eﬀects dominate the wish tobe as accurate and independent as possible. however, we only checked against the variance, see thesection 3


307combining data analytics with team feedback to improve ...


the ability of the team to improve its estimations during the process (rq5); identifythe inaccurate estimates (rq6). herein we brieﬂy motivate and explain these fourresearch questions.


rq3: how accurate are the estimates?we observe the relationship betweenthe estimated and the actual eﬀort, which should linearly correlate: in fact the deﬁ-nition of story points states that the implementation time per story point should besimilar between the story point categories, and proportional between diﬀerent cate-gories (e.g., a 5-point user story is expected to take only half the time of a 10-pointuser story).


rq4: does the eﬀort per story point vary over the course of the project?this research question checks whether the “value” of a story point, i.e.the timespent for a story point, changes over time. in fact, as scrum guidelines show, bothiteration and release planning often use the velocity as a central measurement. thevelocity can be described as the amount of work the development team can completewithin one iteration. for example, a team that has an average velocity of 30 storypoints, can develop as many user stories in one iteration as long as the summedstory point values do not exceed 30 story points. however, this approach might beproblematic if the story points in a project are not linear, e.g. if six 5-point userstories do take much longer than three 10-point user stories.


rq5: does the accuracy of estimates improve during the project?in thisresearch question we investigate whether the performance of the teams in estimatingimprove during the project. in fact, continuous improvement is often regarded asone of the cornerstones of agile software development: for example, scrum deﬁnes aretrospective meeting in which the team members examine the people, relationships,processes, and tools in order to identify possible problems and their causes; then theteam looks for a plan to improve the process and their work in general.


rq6: how many estimates are inaccurate?we identify the wrong estimatesto compute the ratio of inaccurate estimates in each project to discuss them with theprojects teams: correctly detecting the wrong estimates is a necessary step to analysethem and understand their causes.


3.metrics deﬁnition


herein we list the metrics used to answer the research questions and brieﬂy explainthem.


rq1: are estimates getting more similar during the projects?


308


m1 linear regression


• x=sprint number


• y=variance/cov


explanation.we computed the variance and the coeﬃcient of variation of thestory point estimates of the user stories sprint-wise (we ordered user stories by theirsprint membership). the variance measures the variability from the averagely usedstory points and therefore gives an indication of the range of story points used. inaddition to the variance, we compute also the coeﬃcient of variation (cov), which isa standardized measure of dispersion of a distribution and is deﬁned as the ratio ofthe standard deviation σ to the mean µ. the cov deﬁnes the dispersion of the storypoints in a way that does not depend on the variable’s measurement unit as heavily asthe variance does (as an example, for the distributions {1,2,3,5} and {5,8,13,20} thediﬀerence in the variance is 41, while it is 0.05 for the coeﬃcient of variation, despitea big change in the mean value). cov has been used for studying performance timepredictions (e.g., [5]) and on judgement-based predictions of performance time [6].the cov is independent of the unit in which the measurement has been taken andcan be used for comparison between data sets with widely diﬀerent means [21]. finally,we apply a linear regression in order to combine the calculated values as dependentvariables with the sprints as a measurement of the project progress, as explanatoryvariable (in the form cov (or var) = a + b*sprint number).


rq2: are estimates getting smaller or bigger during the projects?


m2 spearman correlation coeﬃcient between the story point value ofall user stories and the sprint number


m3 linear regression


• x=sprint number


• y=story point


explanation.with rq2, we deepen our research of question 1 and observewhether we can identify a correlation between the story point value of a user storyand the project progress. similar to rq1, in rq2 the user stories are ordered by theirsprint membership and a regression analysis is conducted with the sprint numberas independent variable and the story points as dependent variables. we computespearman correlation coeﬃcient [18, p. 396] . for further analysis of this researchquestion we create a box plot showing the estimated eﬀort distribution in each sprint.


rq3: how accurate the estimates are?


309combining data analytics with team feedback to improve ...


m4 spearman correlation coeﬃcient [18, p. 396] between the actual andthe estimated eﬀort


m5 (multiple) linear regression:


• x=story point categories (estimated eﬀort)


• y=implementation hours (actual eﬀort)


m6 p-values of the mann–whitney u test between the implementationtimes per story points of each story point category


explanationto answer rq3, we apply three metrics. firstly, we compute thespearman correlation coeﬃcient between the total implementation time and the storypoints for all user stories. secondly, we check whether the relative character of storypoints holds in practice. thirdly, we calculate the multiple linear regression. finally,since the deﬁnition of story points also states that the implementation time per storypoint should be similar between the story point categories, we pairwise compare thedistributions of the implementation time per story points in the diﬀerent story pointcategories by computing pairwise left-sided mann-whitney u tests [18, p. 293] tocheck whether the actual implementation time of user stories of size i is lower thanthe actual implementation time of user stories of size j, given that j > i.the mann-whitney u test is a nonparametric test of the null hypothesis thattwo populations are the same against an alternative hypothesis, for example that onepopulation tends to have larger values than the other. in contrast to comparablestatistical tests like the t-test, the mann-whitney u test does not require a specialdistribution of the dependent variable in the analysis and can be applied to smallsamples.as a result, each mann-whitney u test delivers a p-value that can beinterpreted for rejecting or accepting the null hypothesis that two distributions arethe same: to be able to manage also categories with few data points without a tooconservative approach, we apply level of α = 0.10, which is considered strict enoughalso when rigor is relaxed in favor of pragmatism [7].we provide the following example to ease the comprehension of the usage of thistest. consider user stories of size 3 and of size 5; we use the mann whitney test tocheck whether implementation times of user stories of size 3 are statistically signiﬁ-cantly diﬀerent (we expect lower) from the implementation times of user stories withsize 5. if they are diﬀerent (test rejected), that implies that the team is properly as-signing user stories to right story point category; otherwise, if the test is not rejected(i.e., implementation times of user stories of size 3 are not statistically diﬀerent fromthose of size 5), that means that the story points categories 3 and 5 are in the practiceindistinguishable: the cause could be either estimation error or the use of too similarcategories of story points, that could be merged into one category.


rq4: does the eﬀort per story point vary over the course of the project?


310


m7 spearman correlation coeﬃcient [18, p. 396] between the story pointvalue and the sprint number (once for all user stories & once per storypoint category)


m8 (multiple) linear regression (once for all user stories once per storypoint category):


• x=sprint number


• y=actual eﬀort per story point


explanation.for a user story with the identiﬁer us x, the actual eﬀort perstory point is computed as follows:


acteffortperstorypointus x = totalimplementationt imeus x


storyp ointsus x.


we then ordered the stories once again according to their sprint memberships,computed the spearman correlation coeﬃcient and applied a multiple linear regres-sion. this was done once for all user stories to observe the overall tendency, and forthe user stories in each story point category.


rq5: does the accuracy of estimates improve during the project?


m9 spearman correlation coeﬃcient between the estimation accuracyand the sprint (for under- & overestimated user stories and overall)


m10 (multiple) linear regression (for under- & overestimated user sto-ries and overall):


• x=sprint number


• y=estimation accuracy


explanation.our concrete measure for the estimation bias is the relative error(re) of a user story. for example, a story with the identiﬁer us x is calculated asfollows:


reus x = estimatedt imeus x−implementationt imeus x


implementationt imeus x.


for example, a user story, that was estimated to take 25 hours and needs 20 hoursto be completed is overestimated by 25%:


reus x = 25−20


20=5


20 = 0.25


thus, an overestimation by 25% describes that the estimation is 25% higher thanthe actual value. this measurement limits underestimations to absolute values be-tween 0% and 100% by construction: for user stories, where the estimated eﬀort is


311combining data analytics with team feedback to improve ...


slightly lower than the actual eﬀort, the diﬀerence in the nominator tends towards 0,and so does the overall result. the 100%-border can be understood by taking in con-sideration, as illustrative example, an estimated eﬀort of 0.1 hours and actual eﬀortof 10 hours:


reus x = 0.1−10


10= −9.9


10= −99%. [9]


as the teams estimated user stories only with story points and did not break downtheir estimation to a time estimation of the tasks, we had to use a proxy measure forthe estimated time in order to apply the re. after a preliminary analysis of the data,we decided to use the the median of the implementation time of all user stories in astory point category as estimated time of a user story in that category. for example:the estimate for a 5-story-point user story is the median of the implementation timeof all 5-story-point user stories in that project. due to this necessary work around,the results of these research questions can only be considered as a proxy of a classicestimation error. in addition, as can be noted from the examples, the directional erroris always negative for underestimated user stories and positive for overestimated userstories.we computed the spearman correlation coeﬃcient [18, p. 396] for estimation ac-curacy over time for under- and overestimations separately. moreover, we applied alinear regression for both types of wrong estimates.


rq6: how many estimates are inaccurate?


m11 rate of over- and underestimates in a project


m12 re interval of over- and underestimates


m13 precision of detected wrong estimates


explanation.for detecting wrong estimates we computed the accuracy as de-scribed in rq5 and applied the following heuristics based on the interquartile rule foroutliers:


1. calculation of the interquartile range (iqr) for the re of all user stories


2. identiﬁcation of overestimations: a user story us x is an overestimation ifreus x > median(res of user stories with same story points)+iqr∗1.5


3. identiﬁcation of underestimations: a user story us x is an underestimation ifreus x < median(res of user stories with same story points)−iqr∗1.5


due to the approximation of the accuracy measure, we validate the identiﬁedwrong estimates with the product owners.


312


4.study context: company and projects description


the study was conducted at techdivision, a medium-size 3 company with approxi-mately 70 employees that develops web applications with agile methodologies. thecompany headquarters are in kolbermoor (south germany) but there is an oﬃcelocated in munich, where most of the projects analysed in this study have beendone. tech division’s development is mostly based on two frameworks: typo3, awidely adopted content management systems in german speaking countries [23], andmagento, a popular content management system for e-commerce websites [17]. thetwo technologies can be combined to provide solutions for content-commerce-systems.overall, techdivision has more than 17 years of experience in developing web applica-tions: they have developed more than 40 magento projects and 100 typo3 projectsand are a certiﬁed partner for both frameworks. in 2011, techdivision switched fromclassic to agile project management. at the time of our analysis, the organization wasstructured in multiple teams, each including developers, product owners, and scrummasters.for our study, we chose projects which used either scrum or scrum variations andwhich estimated with planning poker using story points in the fibonacci-like scale 4.we analysed data from four web application-based development projects: we de-scribe them through a list of context variables selected from the taxonomy proposedby kalus and kuhrmann [10], to whom we added a few additional variables speciﬁcto agile development. the resulting characterisation schema involves ﬁve dimensions:team, internal development context, team client context, project’s objectives, estima-tion process.the product owners ﬁlled their respective projects’ characterisation schemas, thatwe report in an online appendix (5, together with additional details on the course ofthe projects: we consider this information useful to understand our interpretation ofresults and for comparing results of similar future studies.herein we brieﬂy summarize the projects with a qualitative description:


• project 1 was developed by 3 to 7 developers and had a duration of approxi-mately 1.75 years. with 393 developed user stories and approximately 12,700hours of tracked work, it is by far the largest project we consider. the goalof the development was a content-commerce system, i.e. typo3 and magentowere utilized, that had to deal with several neighbouring systems. overall, itwas rated to be highly complex.


• project 2 was about the development of a webshop based on magento. thedevelopment team started with two developers and then reached a constantnumber of six developers. the ﬁnal team remained almost unchanged with only


3accordingtoeuropeanunionrecommendation2003/361/eccategorisationschema:http://goo.gl/ennve54the fibonacci sequence consists of numbers that are the summation of the two preceding num-bers. for example: 0,1, 2, 3, 5, 8, 13, 21. in agile software development, the fibonacci scale is usedfor estimating the relative size of user stories in points5the appendix is available at: https://researchdata.nexacenter.org/2018fcds/appendix.pdf


313combining data analytics with team feedback to improve ...


one team member being replaced by another developer. the project took tenmonths overall, was about 2,500 hours of work, and developed 62 user stories.


• project 3 was the development of a customized web application and took overa year. altogether 206 user stories were developed and a total of 5,600 hoursof work were tracked. the project used mainly new technologies introduced byone team member and therefore the team gathered knowledge on the technologyduring the development.


• project 4 was the smallest project in this study and concerned the relaunch of atypo3 website. it covered 47 user stories, took three month, and 1,400 hoursof work. the development team was co-located, consisted of fours developers,and was constant during the project. moreover, the developers were familiarwith the technology and have already collaborated on a similar project before.


4.1.data extraction and preparation


in all projects, jira 6 was used for project management. therefore we were able toextract all user stories of each project through a jira query 7. this query generatesan excel ﬁle containing several information of each user story that was developedin a speciﬁc project. speciﬁcally, for each user story of the project, the informationprovided by jira is: a unique key identifying the user story; a summary and adetailed description of the user story; the status of the user story (whether it wasclosed or it was still under development); the resolution of the user story (whether itwas ﬁxed or not); the creation time of the user story; the time spent for implementingthe user story; the keys of the sub-tasks constituting the user story, if any; the timespent for implementing the sub-tasks, if any; the estimated story points; the sprintswhich the user story was assigned to. regarding the implementation time, the jiraoutput provides information about the time spent on the speciﬁc jira ticket andthe total implementation time spent, a value including the described time spent plusthe time spent on the sub-tasks of the ticket. this information is not automaticallyprovided by jira but explicitly entered by a developer when he performs work ona user story: for example, if a developer spends ﬁve hours on implementing a userstory and another developer spends two hours on testing and integrating it, eachdeveloper logs his eﬀort in the corresponding user story in jira. if the developmentteam identiﬁes sub-tasks for a user story in the sprint planning, these sub-tasks aregenerated and linked to the corresponding user story in jira. then the developerscan log their implementation time spent to the tasks more speciﬁcally.we noticed that the total time spent was not correct when a related sub-tasks isnot closed correctly. therefore, we developed a java program that calculates the time


6https://www.atlassian.com/software/jira7project = ”projectname” and type = story and (resolution = done or resolution = fixed).the jira output on the sub-tasks is generated by using the following jira query:project =”projectname” and type in subtaskissuetypes(). since the jira web interface can not export morethan 1,000 items at once, it might be required to split the query, e.g. by using the “createddate”attribute


314


spent on the sub-tasks and creates an excel ﬁle that is prepared for further calculationwith r 8, a programming language for statistical computing and graphics.finally, a short note is necessary on the ordering of user stories, which was nec-essary to correctly compute the metrics for rq1 and rq2. since the observed userstories did not contain the exact estimation date, we decided to order them chronolog-ically according to their sprint membership. we assume that the estimation of a userstory is made or reviewed promptly prior to its implementation, for example in thesprint planning meetings. if a user story is assigned to multiple sprints, i.e. if it couldnot be completed in one iteration, we concentrate on the ﬁrst sprint it was assignedto. this sorting seems to be closer to reality than using other existing informationabout the user stories like their creation or resolution dates.


5.results


herein we summarize the results in two tables: we provide a qualitative synopsis intable 2, while we report the metrics for each research question in table 3. each rowis assigned to a project, while the columns contain the following information:


• rq1: the linear regression formulas obtained using the variance and the coeﬃ-cient of variation as dependent variable(m1)


• rq2: the spearman correlation coeﬃcient (m2) and the linear regression ofsprint number vs story points (m3)


• rq3: the spearman correlation coeﬃcient (m4) and the multiple linear regres-sion of estimated eﬀort vs actual eﬀort (m5), and the number of distinct storypoints categories found by applying pairwise the mann whitney u betweengroups (m6)


• rq4: the spearman correlation coeﬃcient (m7) the multiple linear regressionof sprint number vs actual eﬀort (m8)


• rq5: the spearman correlation coeﬃcient (m9) and the regression line accuracyvs sprint number (m10), both for under and over estimations


• rq6: the proportion of under and over estimations (m11), the re range (m12)for both under and over estimations, and the precision (m13) of detected wrongestimates from the validation with the product owners.


together with the regressions correlation formulas, we report also the obtainedr2.in addition, an asterisk close to the coeﬃcient correlations, signals that the correlationis signiﬁcant with p value ≤0.05given the large amount of data (13 metrics multiplied by 4 projects), we do notreport in this paper all the graphs that we computed and analyzed; however, weprovide an online website9, which also contains the following additional information:


8http://www.r-project.org/9all results and descriptive statistics are available at https://researchdata.nexacenter.org/2018fcds/


315combining data analytics with team feedback to improve ...


• rq1: the relation between the variance/cov and sprint number is visualisedwith a scatter plot including a regression line to give a more detailed overviewof the trend direction. we also provide boxplots of the story points for eachsprint and the mean of the estimated story points in the sprints.


• rq2: the correlation graphs can be consulted.


• rq3: additionally we report the correlation between the story point size of auser story and its implementation time, the box plots also shown in fig.1together with the table of all pairs of mann whitney tests computed betweenstory points categories.


• rq4: the relation between the implementation time per story point is visualizedwith a scatter plot including a regression line to give a more detailed impressionof the trend direction


• rq5: we report graphs of the regression lines separately for over- and underes-timations.


• rq6: in addition to the data displayed in the result table 3, the online appendixshows in details the outlier detection analysis, also per story point category.


projrq1


estimations


variance


rq2


estimations


size


rq3


estimation and


actual effort


rq4


effortper


story point


rq5


accuracyof


estimations


rq6


wrongestima-


tions


p1decreasinguntil a teamturnover,thenin-creasing


slightlydecreas-ing


almostquadratic


costantimproving(overest.),constant(under-est.)


veryin-accurate,especiallyover-


p2decreasingdecreasinglinearslightlyincreasing


slightlydecreasingaccuracy


quiteinaccu-rate


p3decreasingconstantlinearslightlydecreasing


decreasingaccuracy


veryinaccu-rate


p4decreasingslightlydecreas-ing


quadraticslightlyincreasing


improvingaccuracy


quiteinaccu-rate


table 2. textual synopsis of the analysis results for each research questions


316


rq1estimations variancerq2estimations sizesrq3estimation and actual effort


m1regr. var.


m1regr. cov


m2spearman


m3regr.


m4spearman


m5regr.


m6categories


proj1


26.84-0.61x(r2=0.18)


0.91-0.01x(r2=0.17)


-0.117*5.7-0.08x(r2=0.02)


0.637*2.58+1.97x+0.05x2


(r2=0.51)


7


proj 257.47-2.74x(r2=0.23)


0.73-0.01x(r2=0.04)


-0.352*10.44-0.33x(r2=0.07)


0.623*0.9+1.43x+0x2


(r2=0.45)


5


proj 3193.35-15.12x(r2=0.30)


0.89-0.01x(r2=0.07)


0.00810.88-0.2x(r2=0.00)


0.586*1.46+1.28x+0x2


(r2=0.37)


5


proj 418.3-2.81x(r2=0.46)


0.81-0.02x(r2=0.02)


-0.1355.27-0.46x(r2=0.05)


0.712*9.88+1.19x+0.38x2


(r2=0.76)


5


rq4effort per story pointrq5accuracy of estimationsrq6wrong estimations


m7-spear.


m8 - regm9-spear.


m10 - regr.m11-rate.


m12 -interval


m13-precision


proj 1-0.0132.94+0.04x+0x2


(r2=0.00)


over:-0.077under:-0.055


over: 3.37-0.049x(r2=0.00)under:-0.35-0.002x(r2=0.00)


over: 11%under:4%


over:[1.75, 34]under:[-0.52, -0.88]


72%


proj 20.1061.6+0x+0x2


(r2=0.01)


over:0.064under:-0.146


over: 1.21+0.074x(r2=0.02)under:-0.36-0.003x(r2=0.01)


over:6%under:3%


over:[4.875, 13]under:[-0.55, -0.66]


83%


proj 3-0.165*0.66+0.36x-0.03x2


(r2=0.02)


over:0.238under:-0.142


over:-0.16+0.314x(r2=0.09)under:-0.4-0.011x(r2=0.02)


over:8%under:7%


over:[1.88, 22]under:[-0.74, -0.95]


77%


proj 40.1994.4+1.61x-0.23x2


(r2=0.01)


over:-0.34under:-0.097


over: 1.18-0.147x(r2=0.08)under:-0.28+0.09x(r2=0.00)


over:6%under:4%


over:[1.33, 2.12]under:[-0.58, -0.62]


80%


table 3. results


317combining data analytics with team feedback to improve ...


●


●●●


●


●


●


●


●


●●


●


●


●


●


●


●


0


30


60


90


00.5123581320


story point value


implementation time


rq3: project 1 − impl.time in the story point categories


(a) rq3 - project 1


●


●


●


0


20


40


60


80


00.512358132040


story point value


implementation time


rq3: project 2 − impl.time in the story point categories


(b) rq3 - project 2


●●


●


●


●


●


●


●


●


●


●


●


0


25


50


75


100


12358132040


story point value


implementation time


rq3: project 3 − impl.time in the story point categories


(c) rq3 - project 3


●


●


●


●


0


30


60


90


0.51235813


story point value


implementation time


rq3: project 4 − impl.time in the story point categories


(d) rq3 - project 4


figure 1. boxplots of implementation times per story point categories. the dottedlines show overlapping categories identiﬁed with the left side mann whitney test


318


6.discussion


our interpretation of results are based on the projects contexts and on qualitativefeedback from the product owners of the corresponding projects. concerning the latterone, we usually obtained it by bringing the analysis results printout to discussion withthe product owners. for project 1, the feedback was collected diﬀerently: the wholeteam participated and the results were continuously displayed on a wall in a commonspace, so that each team member was able to add his/her own ideas and observationsat any time: this was intended as a simulation of the approach described in [22]. wecould not apply the same strategy to the other projects because not all team memberswere located in munich: however all product owners were there, so it was possible togather their comments. we continue the remainder of the discussion per rq, with aﬁnal short summary.


rq1: are estimates getting more similar during the projects? - rq2: areestimates getting smaller or bigger during the projects?we observed fromrq1 that the range of story points used got smaller during the course of the projects.complimentary information to understand the cause of such variation comes from theresults of rq2, which showed that the estimated size of user stories slightly decreasedfor three projects over the time. in project 1, the tendency to use less story pointvalues for estimation was a symptom of a conscientious decision the team made aftersome problematic iterations before sprint 22: team members agreed to avoid the esti-mation of 13 and 20 story point stories, splitting them into smaller stories. however,this decision was withdrawn due to a change in the development team (∼26 sprint)in the further course of the project: this also explains the increase of the variationin a later phase that we reported in table 2. we do not have similar explanationsfor the other projects. however when checking descriptive statistics together withthe results from rq2, we observe that projects 2 and 4 display a (slightly) negativecorrelation between the estimated size of user stories and the project progress: weknow therefore that decrease in the usage of the full range of the story points is dueto a higher usage of smaller stories. however, we do not have evidence, as it was forproject 1, to interpret it as a symptom of a problem in managing large user stories,or whether this happened simply because the largest stories were at the top of theproduct backlog. additionally, we cannot exclude the possibility that team membersunconsciously focused on less story points categories with the course of the project.


rq3: how accurate the estimates are?regarding rq3 results, the positivespearman coeﬃcient (metric m4) conﬁrmed that higher estimates corresponded pro-portionally to higher implementation times. we remember the reader that the rationalof such a question was to check the relative character of user stories, e.g. a 5-pointuser story should take half of the time of a 10-point user story: therefore one wouldassume a linear regression line describing the relation between the story points of auser story and its implementation time. this was true for projects 2, 3 and partiallyfor project 1, while the fourth project showed a quadratic growth in implementationtime: this would mean that, for example, a 10-point user story needs more than twice


319combining data analytics with team feedback to improve ...


as much time as a 5-point user story. however, the usage of fibonacci scale wouldsupport also a quadratic relationship, as considered also by a story point analogy de-scribed by cohn [3, p. 52] : in that example, each story point value is illustrated as aglass while the needed eﬀort of a user story is represented by water. a user story mayonly be assigned to a story point value if its eﬀort ﬁts into the glass: whenever theeﬀort of a user story is too big for one bucket, the next bigger story point category hasto be chosen. in case a fibonacci scale is used, as in the projects analysed, a diﬀerentbehaviour may occur: in figure 2, the blue line describes a perfectly linear story pointmeaning where a 40-point user story exactly takes twice the eﬀort of a 20-point story,while the red line indicates a possible story point development according to cohn’sanalogy. for this reason, we do not consider a slightly super-linear relationship assymptom of a problem in the estimation process or in the project in general.


figure 2. visualization of the “glass” analogy for story points


rq4 - does the eﬀort per story point vary over the course of the project?concerning rq4 results, we observed that the general deﬁnition of story points asa relative measurement was not valid for three of the four observed projects as thevalue of a story point was not constant in the diﬀerent story point categories. inparticular, in projects 2 and 3 the middle-sized user stories (respectively 5 storypoints and 8 story points) required more in terms of time, while in project 4 thishappened for smaller user stories. thus, it has to be questioned whether a predeﬁnedestimation scale with numerical values is beneﬁcial for following planning activitiesin agile projects, e.g. a team might be able to deliver a 8-point user story withinone sprint while the combination of a 3-point and a 5-point user story can not becompleted due to a higher cost per story point in the 5-point category.


rq5: does the accuracy of estimates improve during the project?regard-ing the capability of the teams to improve in terms of estimation accuracy, we couldobserve it only in project 4 (and only for overestimations in project1). in project 1,


320


we observed extreme underestimations after sprint 16, which coincides with a changein the software development process: after sprint 15 the team switched from scrum toan approach kanban-like (but keeping estimations) for a period of two months beforereturning to scrum: thus, we believe that it was the change of approach which haslead to the wrong estimates. another ﬁnding was that the number of extremely wrongestimates decreased with a shortened iteration length of one week from sprint 26 on.what the development team identiﬁed as a potential reason for this change was thepossibility of a more detailed sprint planning for one than for two weeks. however,this did not hold in project 2 where the iteration length was similarly shortened toone week. together with the product owner, we were able to identify potential rea-sons for the decreasing accuracy in project 3: after sprint 5 the project was stoppeddue to the customer’s dissatisfaction. after a break, all remaining user stories wereestimated more vaguely in order to give the customer an impression of the expectedcosts. the project was then resumed with a ﬁxed budget and the assurance of thedesired functionality.due to the time pressure the assigned estimates where notre-checked in the following sprints and during the sprint planning meetings the userstories were handled independently from their estimate. in project 4, the productowner identiﬁed the team’s learning from complex tasks in the ﬁrst iterations as amain reason for the improvement in estimating. the team used to have ﬁxed ap-pointments and structures for their sprint meetings, including the grooming meeting.thus, the approach in project 4 is the best representation of the targeted continuousimprovement through the inspect-and-adapt approach in scrum. comparing this tothe poor results of project 3, where the team did not have grooming meetings in thesecond half of the project, a ﬁxed structure in the meetings seems to be beneﬁcial forthe improvement of estimates in a project.


rq6: how many estimates are inaccurate?finally, the results of rq6 showthat the projects 1 and 3 not only have the highest rate of wrong estimates (15%),but also that the estimates are extremely wrong: in project 1 the re of the overes-timations range from 1.75 to 34, i.e. the estimated eﬀort exceeds the actual eﬀort bya minimum of 175% up to a maximum of 3400%. project 3 is similar in this regardas the upper border of the overestimations is 2200% here. projects 1 and 3 are thetwo projects with the greatest number of changes to the software process as both hada longer break where scrum was interrupted: while project 1 interrupted scrum dueto a process change to kanban-like process, project 3 had to be stopped due to prob-lems in the negotiation with the customer. as explained in rq5, both interruptionsresulted in problems with the estimation accuracy. project 4, by contrast, was char-acterized as the project with the most constant software development process as therewere no interruptions to the project and further regular meetings helped to ensure awell-maintained product backlog. from the perspective of the product owner, theseestablished structures were beneﬁcial to the estimation, planning, and the projectsuccess in general. the discussions with the product owners about the validationof the wrong estimations detected by our heuristic, revealed that underestimationswere often caused by a falsely assumed standard functionality of typo3 or magento,technical problems, e.g. an inevitable refactoring, and or unnoticed side tasks like


321combining data analytics with team feedback to improve ...


cross-browser support or intensive testing. in contrast to underestimations, overesti-mations are often caused by a too high weighting of uncertainties, leading developersto integrate an actually unnecessary buﬀer. in these cases the teams discuss multiplesolutions for a user story and then credits the uncertainty of which solution might beappropriate with a higher overall estimate.


summarythe evidence we collected let us identify a few symptoms of problems:


• the reduction of the number of story points over the course of the projects, witha tendency to use smaller stories (rq1, rq2; all projects);


• not constant value of a story point (rq4; projects 2,3,4)


• a degradation of the accuracy of estimations, with very large errors (rq5, rq6;projects 1,2,3).


therefore, according to our interpretation of results and the feedback collectedfrom the team members, and excluding external factors (e.g., team changes due toleaves), we derived the following explanations:


• e1 too many items in the estimation scale are not distinguishable by teammembers


• e2 the usage of a numerical scale is misleading


• e3 estimating new user stories without an explicit and shared reﬂection onprevious estimations can lead to extreme wrong estimation


7.improvement proposal


7.1.treatments selection


based on discussion of result and our explanations, we derived the following hypothe-ses:


• h1. a non numerical scale with fewer items allow team members to allocatebetter user stories to estimation categories.


• h2. mechanisms that forces the team members to reﬂect on previous estima-tions improve the accuracy of the estimations.


we declined these hypotheses into three treatments to be applied in the estimationprocess of tech division.


322


t1 estimation unit and scale.as discussed in previous section, we observedthat less and smaller user stories were used over the course of a project. accordingto the knowledge gathered, the cause is a natural tendency of estimators to handlea few categories and that a numerical scale for user story estimation was misleading.therefore, we introduced an estimation scale with only ﬁve diﬀerent categories (whichwas the number of distinguishable story points categories in three out of four projects,as reported in table 3 and figure 1d): the categories are abstract and use commont-shirt sizes to symbolise the amount of eﬀort needed for the completion of a userstory. the new estimation scale discussed with the team members resulted in: s, m,l, xl, and xxl. in addition, a ”can’t or won’t estimate“ option is available, whichdisplays that a user story either cannot be estimated due to the uncertainty or thatthe user story is too large to be assigned to a category.


t2 analogy-based estimation.we introduced an analogy-based estimation pro-cess: we wanted to encourage the team to compare new user stories to already es-timated and implemented ones. in the designed process, the developers can use theanalogy in their discussion about a user story and they are always forced to check itsestimation before ﬁnally assigning it to a speciﬁc estimation category.


t3 estimation retrospective.based on the success factors of project 4 in termsof accurate estimations, which were a problem for the other projects, and inspired bythe inspect-and-adapt principle of scrum, we introduced an estimation retrospective,which is used to examine the statistical over- and underestimated stories from thelast sprint. in our opinion this should recreate a learning process that helps the teamto avoid wrong estimates and improve their estimation accuracy during a project.


7.2.metrics


to quantitatively measure the eﬀect of the treatments and verify our hypothesis, wedecided to rely on two metrics from the set of those used in the ﬁrst analysis of thefour projects. the main reason rely on the change of measurement scale from ratioto ordinal scale (but with nominal items). in order to compute most of the metrics,we would have had to transform the nominal scale into a numerical one, assigning forexample 1 to s, 2 to m, and so on. however, the measurements would be misleadingbecause in the former measurement cycle user story sizes were expressed in terms ofitems of a fibonacci scale. assigning the t-shirt sizes to the items of a fibonacci isalso a not a valid procedure, because the meaning of the categories in the two scalesare totally diﬀerent. for this reason we opted for relying only on measurements on theimplementation times of each t-shirt size category, without regressions. the resultingmetric set is reported in table 4.since we could not exclude interdependencies between the treatments, te best wayto isolate their eﬀects would be to apply them one by one. however, due to feasibilityreasons, the preference of the company and the preference for pragmatism, we testedthe treatments in a unique cycle of experimentation. hence, to identify and isolate


323combining data analytics with team feedback to improve ...


hypothesismeasurement


h1 - a non numerical scale with feweritems will allow team members to al-locate better user stories to estimationcategories


m7 number of undistinguishable esti-mation categories (identiﬁed throughmann whitney test)


h2 - mechanisms that forces the teammembers to reﬂect on previous estima-tions will improve the accuracy of theestimations.


m12 rate of over and underestimatesm13 re interval of over- and underes-timates


table 4. summary of the treatments


the eﬀect of each treatment, we complemented the measurement on the process witha qualitative evaluation consisting of a short questionnaire ﬁlled at the end of anestimation meeting, to gather the perspective of the team members. the questionsused are reported in table 5. given the low number of team members, we used onlydescriptive statistics for the analysis.


# idquestionanswer options


q1”the number and the name of the cat-egories helped me to estimate user sto-ries”: in which degree this statement istrue for you?


no / only the abstract cate-gory name / only the numberof categories (5) / yes


q2if not, why did categories did not helpyou ? what could be improved ?


free text


q3”the use of comparison to referenceuser stories helped me to estimate userstories” : in which degree this state-ment is true for you?


likert scale from 1(stronglydisagree)to5(stronglyagree)


q4if not, why did the comparison did nothelp you ? what could be improved ?


free text


q5”the grooming retrospective helped usto ﬁnd a good practice for our estima-tions” in which degree this statement istrue for you?


likert scale from 1(stronglydisagree)to5(stronglyagree)


q6if not, why did the retrospective nothelp you? what could be improved ?


free text


table 5. questionnaire at the end of the estimation meeting


324


7.3.the new estimation process


figure 3 displays the course of an estimation meeting according to modiﬁed process,which we are going to describe through its main characteristics.


estimation wall.for the estimation meetings we prepared an “estimation wall”,showed in figure 4: the center of the wall is a whiteboard, where the estimationcategories are visualised as columns where user stories, represented by post-its, canbe physically assigned after their estimation. above the whiteboard, the descriptionestimation process takes place, as well as our deﬁnition of the estimation unit. rightto the whiteboard, there is room to present information on the user stories completedin the last sprint. the team will use it for the retrospective to identify best practicesfor further estimation meetings, which will be inserted in the checklist above.


estimation meeting - part 1each estimation meeting should take place in frontof the estimation wall with a computer screen visible to all team members: accordingto the vision of the fast feedback cycles [22], practitioners should rely on the use ofdata (interactive) visualisations for their activities. therefore the team can use thecomputer to access the original user story in jira and for its discussion (e.g.,to esti-mate user story is necessary to examine the current status of the product increment).in addition, in our process an estimation meeting begins with a retrospective, wherethe development team reﬂects on diﬃcult user stories that were developed during thelast sprint (e.g. very inaccurate estimates). for this purpose, we wrote an r scriptwhich generates box plots for the implementation time per estimation category, oneeach for all user stories in the project and for the user stories from the last sprint.moreover, the script produces a list of the last sprint’s user stories with importantpieces of information like the estimated category, the implementation time or thenumber of assigned sub-tasks. in order to structure the retrospective and collect itsresults, the box plots and the list of user stories are prepared on a ﬂip chart. if theteam has identiﬁed very good estimations from the last sprint, then it tries to derivebest practices and write them on a post-it. if the team has identiﬁed a wrong esti-mation, it can re-assign the user story to the correct category: in this way, the teamcan avoid wrongly estimated user stories for future comparisons.


estimation meeting - part 2in the second part of the meeting the actual es-timation of user stories takes place. similar to planning poker the user stories areestimated sequentially. in the beginning, the product owner presents the user storyand shares his knowledge about the requirement with the team. the team then dis-cusses the user story in a way so that each estimator can derive an estimation forhimself. since the estimation meeting is hold in front of the estimation wall, the useof analogy is easier and more prominent. a common problem in analogy-based esti-mation techniques is that often a initialization phase is needed: if there is no referenceuser story in the estimation categories, no comparisons can be made. we tackled thisissue by conducting a training on the new estimation process, where we let the team


325combining data analytics with team feedback to improve ...


figure 3. the ﬂow of an estimation meeting according to the changed process


estimate user stories from the last sprints: this helped the team not only to becomefamiliar with the new approach, but also provided reference user stories.the team plays a rock-paper-scissors variant to coordinate the single estimates:


326


figure 4. example of the estimation wall at techdivision


each estimator simultaneously reveals to which of the ﬁve estimation categories (s)hewould assign the discussed user story by the number of ﬁngers (s)he shows to thegroup. while one ﬁnger indicates a s user story, ﬁve shown ﬁngers stand for a xxluser story. additionally, an estimator can refuse an estimation by showing a ﬁst tothe group. this indicates that the user story can not be estimated or that is toobig for the completion in one sprint. if all participants agree in their estimation,the estimation of the user story has to be conﬁrmed in a next step by comparingit to already estimated and completed user stories in the according category. if theteam members vary in their estimation, the user story has to be discussed again (agood approach might be to have the highest and the lowest estimator explain theirestimations to capture the diverging reasons). moreover, if the estimations of therock-paper-scissor variant diﬀer in two categories, it might be useful to pin the userstory between the categories and compare it to the user stories of each category.this might help to identify which estimation might be more appropriate. after thediscussion is completed the team plays the rock-paper-scissors variant once again tosee whether it can reach a common estimation now. however, if multiple rounds donot lead to a common estimation for a user story or if the team thinks it cannot beestimated, then the user story has to be “refused” in this estimation meeting andthus is not ready for implementation. ideally, the results of the discussion and thereasons playing into the estimation decision are noted on the post-it representing theuser story. this makes the user stories more comparable for further estimations andmight help the team to identify estimation problems during the next retrospective.


327combining data analytics with team feedback to improve ...


7.4.project hosting the experimentation


the project context in which the treatments were introduced was similar to the oneof project 2: it was the same team developing a comparable webshop with magento.the eﬀorts for the user stories in the project were ﬁrst estimated in ideal hours ina planning poker-like meeting. but since the team heavily underestimated the userstories with this approach, we got the chance to introduce the estimation approachwe had designed. the project had been worked on for about 1.5 months before ourchange in the estimation process was established.we prepared the estimation wall in the room where the development team wasco-located. the deﬁnition of our estimation unit was discussed with the team andﬁnally presented and explained in a blog post in the company’s wiki and also addeda short description to the estimation wall.we provide in the appendix the same contextualisation schema built for the pre-vious projects.


8.experimentation results


we were able to observe seven one-week iterations that were conducted according tothe presented estimation approach. the team was constant over the time except forone developer leaving after the second iteration. it is important to note that our ob-servation did not start with the beginning of the project, nor could we accompany theproject to its completion due to the fact that two of the co-authors had to leave. weparticipated in three of the estimation meetings and assured that they were conductedaccording to the newly established process.the qualitative analysis is based on these three estimation meetings: the descrip-tive statistics on the questionnaire answers are reported in figures 6, 7 and 8.the quantitative analysis covers all seven sprints: in that period the developmentteam completed 34 user stories, which covers approximately half of the total courseof the project. the results are the following ones.


m7 the mann-whitney u test provided p-values greater than 0.05 only in compar-isons including the xl estimation category (see table 6 and figure 5). since thexl category can be ignored due to its small sample size, the null hypothesis ofsimilar groups is rejected for all estimation categories. hence, the actual eﬀortof the diﬀerent new categories diﬀered from each other.


m12 the rate of over and under estimates are, respectively, the following: 12 %(4/34) and 3 % (1/34)


m13 the re interval is 1.19 to 2.57 for overestimations, and -0.494 for the onlyunderestimation detected.


328


0


20


40


60


smlxlxxl


t−shirt size


implementation time


impl. time per estimation category


figure 5. estimation approach - results of rq3 (m6): box plots describing theimplementation time in each story point category


mlxlxxl


s0.02741e-040.1250.003m-0.00750.250.0061l--0.19240.004xl---0.2


table 6. estimation approach - results of rq3: pairwise mann-whitney u test forthe implementation time in the story point category


figure 6. question on the estimation category


329combining data analytics with team feedback to improve ...


figure 7. question on the use of analogy


figure 8. question on the retrospective


9.experiment results discussion


the quantitative analysis lead to consider two positive eﬀects of the treatment on theestimations.firstly, the implementation time of the ﬁve used estimation categories could bedistinguished very well, as the box plot and the mann whitney test also show. thisconﬁrmed that the 5 items might be a suﬃcient number to use in a scale for estimatinguser stories. however, we also observed that the category xl was used only once,therefor we do not exclude the possibility that even 4 items could be suﬃcient in aproject like the one we analysed.secondly, the detected false estimations were not that extreme compared to theprojects in the ﬁrst measurement cycle. the one detected underestimation has anaccuracy of -49.7%, indicating that it actually needed twice the estimated eﬀort. incomparison, we noticed an improvement from 10% to 45% with the previous projects.the overestimations have a relative directional error between 1.19 and 2.57: this valueis at the same level with the one from project 4, which ranges from 1.33 to 2.12.besides these positive eﬀects, there was a still a high percentage of wrong esti-mations: in total, 14.7% of the 34 user stories were identiﬁed as wrongly estimated,according to our detection algorithm. however when discussing the wrong estimationswith the product owner about the results, we discovered that one of detected userstories could be removed from the inaccurate ones, because it was assigned the wrongissue type in jira (the overestimation was actually a time-boxed technical spike).hence, the detection rate was 11.8% (and consequently precision of the heuristic is80%), but still did not improve with respect to the previous projects analysed.


330


the survey results showed that the team perceived the changes to the estimationunit and scale (t1) as most useful: in all three surveys the participants agreed thatboth the number of categories and the abstract name of the categories helped inestimating the user stories. nevertheless, one answer to the open questions identifya potential threat in the rock-paper-scissors game: the respondent fears that theordinal scale of the t-shirts sizes might be undermined by the number of ﬁngers usedto indicate the estimated category.the feedback on the analogy mechanisms (t2) is also considered to be useful bymost of the team members: in all three surveys, 11 of the 14 respondents agreed thatthe use of analogy helped in estimation of user stories.finally, the estimation retrospective (t3) seems to have the smallest eﬀect on theresults from the quantitative analysis: 70% of the respondents did not agree that theretrospective helped to ﬁnd good practices for further estimations.therefore, by combining the quantitative and qualitative analysis, the evidencecollected indicate that the improvements observed are mostly likely an eﬀect of thechanges to the estimation unit and the explicit use of analogies during the estimationprocess. therefore we accept both our hypotheses, but we exclude the retrospectivemeeting from the new process.


10.limitations and future work


although the improvements observed in the new project and the higher accuracy ofestimates, we recognize that the proportion of inaccurate estimates remained at aboutthe same level of the projects with the previous estimation process. we discussed thisissues with the company, and decided to devote a follow-up study on this. in thiscontext, and in the purpose of automating the improvement approach presented in thispaper10 we implemented an interactive visualization which displays the distributionsof the user stories implementation eﬀorts, highlighting the outliers (according to adiﬀerent detection algorithm): the team is able to inspect the supposedly wrongestimations, validate them and leave feedback directly on the web application. atthe time of writing, the new data analysis is ongoing. a second limitation of thisstudy is related to the duration of project 5 analysis: due to research staﬀmoving,only half of the project could be analyzed. a third limitation is the lack of treatmentisolation (all were tested at the same time): we could not ﬁx this threat, but byconducting a qualitative validation on the quantitative ﬁndings we could control it.finally, our results cannot be generalized to other projects and companies: howeverwe provided in appendix a detailed project characterization that should serve as aguide for applying the proposed improvement methodology in other companies andcompare the achieved results with ours.


10the work is part of a broader idea of tuning data analysis with fast feedback cycles from researchstakeholders. a description of the approach has been presented at the 37th international conferenceon software engineering in 2015, where we showed the preliminary results [22] of testing the approachon user stories text analysis. we observed that a double feedback mechanism notably improved theprecision of the data analysis and the quality of the data gathered


331combining data analytics with team feedback to improve ...


11.conclusions


we conducted a research to understand the causes of wrong estimates in softwareagile development and consequently improve the estimation process. this study wasconducted in a german company developing web applications with agile processes.our improvement methodology combined software data analytics (from four projects)with elicitation of teams’ feedback, which helped us to identify the following mainissues: a tendency to use less story points and smaller stories over the course of theprojects; a non constant value of a story point; a degradation of the estimationsaccuracy, with a presence of very large errors. we identiﬁed the possible explanationsfor those problems and subsequently deﬁned three major changes in the estimationprocess: a non numerical scale for story points with less items; an analogy-basedestimation; retrospectives analyses on the accuracy of previous sprints estimations.the new estimation process was applied on a new project, and we could observe apositive eﬀect, with an improvement of the accuracy from 10% to 45% with respectto the previous analyzed projects.we consider as our main contributions i) the improvement methodology to identifyand solve estimation issues in agile software development projects, and ii) the projectcharacterization schema that should serve as a guide for comparing further replicationof this study in other companies.


acknowledgment


we would like to thank sacha storz and the whole team in the partner company:without their restless availability and cooperation this experimentation would havenot been possible.

